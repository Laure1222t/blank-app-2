import streamlit as st
import fitz  # PyMuPDF
import re
import time
import requests
import json
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import tempfile
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¡æ¬¾å¼æ”¿ç­–æ¯”å¯¹åˆ†æå·¥å…·",
    page_icon="ğŸ“œ",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .stButton>button {
        margin-top: 1rem;
    }
    .analysis-box {
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 1rem;
        margin-top: 1rem;
        background-color: #f9f9f9;
    }
    .matched-clause {
        border-left: 4px solid #28a745;
        padding: 0.75rem;
        margin: 1rem 0;
        background-color: #f8fff8;
    }
    .difference-section {
        border-left: 4px solid #ffc107;
        padding: 0.75rem;
        margin: 0.5rem 0;
        background-color: #fffcf2;
    }
    .summary-box {
        border: 1px solid #007bff;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        background-color: #f0f7ff;
    }
    .parse-info {
        font-size: 0.9rem;
        color: #6c757d;
        margin-top: 0.5rem;
    }
    .clause-item {
        padding: 0.5rem;
        margin: 0.25rem 0;
        border-radius: 3px;
        background-color: #f0f2f6;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'target_clauses' not in st.session_state:
    st.session_state.target_clauses = {}  # {æ¡æ¬¾å·: å†…å®¹}
if 'compare_files' not in st.session_state:
    st.session_state.compare_files = {}  # {æ–‡ä»¶å: {æ¡æ¬¾: {}, åˆ†æç»“æœ: {åŒ¹é…ç»“æœ: {}, æ€»ç»“: ""}}}
if 'current_file' not in st.session_state:
    st.session_state.current_file = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = os.getenv("QWEN_API_KEY", "")
if 'max_clauses' not in st.session_state:
    st.session_state.max_clauses = 30  # é»˜è®¤æœ€å¤§æ¡æ¬¾æ•°
if 'parse_precision' not in st.session_state:
    st.session_state.parse_precision = "ä¸­ç­‰"  # è§£æç²¾åº¦

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“œ æ¡æ¬¾å¼æ”¿ç­–æ¯”å¯¹åˆ†æå·¥å…·")
st.markdown("ç²¾ç¡®è§£ææ”¿ç­–æ–‡ä»¶æ¡æ¬¾ï¼ŒæŒ‰ç¼–å·åŒ¹é…å¹¶åˆ†æåˆè§„æ€§ä¸å·®å¼‚")
st.markdown("---")

# æ¡æ¬¾æå–è®¾ç½®
st.sidebar.subheader("æ¡æ¬¾æå–è®¾ç½®")
st.session_state.max_clauses = st.sidebar.slider(
    "æœ€å¤§æ¡æ¬¾æ•°é‡", 
    min_value=0, 
    max_value=50, 
    value=st.session_state.max_clauses,
    help="è®¾ç½®ä»æ–‡ä»¶ä¸­æå–çš„æœ€å¤§æ¡æ¬¾æ•°é‡ï¼Œ0è¡¨ç¤ºæ— é™åˆ¶ï¼ˆæœ€å¤š50æ¡ï¼‰"
)

# è§£æç²¾åº¦è®¾ç½®
st.session_state.parse_precision = st.sidebar.select_slider(
    "æ¡æ¬¾è§£æç²¾åº¦",
    options=["å®½æ¾", "ä¸­ç­‰", "ä¸¥æ ¼"],
    value=st.session_state.parse_precision,
    help="å®½æ¾ï¼šæå–æ›´å¤šå¯èƒ½çš„æ¡æ¬¾ï¼›ä¸¥æ ¼ï¼šåªæå–æ˜ç¡®ç¬¦åˆæ ¼å¼çš„æ¡æ¬¾"
)

# APIé…ç½®
with st.expander("ğŸ”‘ API é…ç½®", expanded=not st.session_state.api_key):
    st.session_state.api_key = st.text_input("è¯·è¾“å…¥Qwen APIå¯†é’¥", value=st.session_state.api_key, type="password")
    model_option = st.selectbox(
        "é€‰æ‹©Qwenæ¨¡å‹",
        ["qwen-turbo", "qwen-plus", "qwen-max"],
        index=0  # é»˜è®¤ä½¿ç”¨è½»é‡ç‰ˆ
    )
    st.caption("æç¤ºï¼šå¯ä»é˜¿é‡Œäº‘DashScopeå¹³å°è·å–APIå¯†é’¥")

# ä¼˜åŒ–çš„PDFè§£æå‡½æ•° - å¢å¼ºæ¡æ¬¾æ‹†åˆ†èƒ½åŠ›
def parse_pdf_by_clauses(file, max_clauses=30, precision="ä¸­ç­‰"):
    """è§£æPDFæ–‡ä»¶å¹¶æŒ‰æ¡æ¬¾å·æå–ç»“æ„åŒ–æ¡æ¬¾ï¼Œä¼˜åŒ–æ‹†åˆ†é€»è¾‘"""
    try:
        with st.spinner("æ­£åœ¨è§£ææ–‡ä»¶å¹¶æ‹†åˆ†æ¡æ¬¾..."):
            doc = fitz.open(stream=file.read(), filetype="pdf")
            total_pages = len(doc)
            full_text = ""
            
            # é€é¡µè¯»å–æ–‡æœ¬ï¼Œä¿ç•™é¡µé¢ä¿¡æ¯
            for page_num, page in enumerate(doc, 1):
                page_text = page.get_text()
                # æ¸…ç†é¡µé¢æ–‡æœ¬å¹¶æ·»åŠ é¡µåˆ†éš”ç¬¦
                full_text += f"\n\n[[PAGE {page_num}]]\n{page_text}"
            
            # æ–‡æœ¬é¢„å¤„ç† - å¢å¼ºæ¡æ¬¾è¯†åˆ«
            full_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', full_text)  # ç§»é™¤æ§åˆ¶å­—ç¬¦
            full_text = re.sub(r'(\r\n|\r|\n)+', '\n', full_text)  # ç»Ÿä¸€æ¢è¡Œç¬¦
            full_text = re.sub(r'[^\S\n]+', ' ', full_text)  # æ›¿æ¢éæ¢è¡Œç©ºç™½å­—ç¬¦ä¸ºç©ºæ ¼
            full_text = re.sub(r'(\d+)\.(\d+)', r'\1.\2', full_text)  # ä¿®å¤æ•°å­—é—´çš„ç‚¹
            full_text = full_text.strip()
            
            # æ ¹æ®ç²¾åº¦é€‰æ‹©ä¸åŒçš„æ¡æ¬¾æå–æ¨¡å¼
            clauses = {}
            
            # ä¸»è¦æ¡æ¬¾æ¨¡å¼ï¼šç¬¬Xæ¡
            primary_pattern = re.compile(r'(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+\s*æ¡\s+.*?)(?=ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+\s*æ¡\s+|$)', re.DOTALL)
            primary_matches = primary_pattern.findall(full_text)
            
            if primary_matches:
                # ä»ä¸»è¦æ¨¡å¼æå–æ¡æ¬¾
                for match in primary_matches:
                    clause_num_match = re.search(r'ç¬¬([é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+)\s*æ¡', match)
                    if clause_num_match:
                        clause_num = clause_num_match.group(1)
                        # æ¸…ç†æ¡æ¬¾å†…å®¹
                        clause_content = re.sub(r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+\s*æ¡\s*', '', match).strip()
                        # ç§»é™¤é¡µç æ ‡è®°
                        clause_content = re.sub(r'\[\[PAGE \d+\]\]', '', clause_content)
                        
                        # æ ¹æ®ç²¾åº¦è¿‡æ»¤æ¡æ¬¾
                        if clause_content:
                            if precision == "ä¸¥æ ¼" and len(clause_content) > 50:
                                clauses[clause_num] = clause_content
                            elif precision == "ä¸­ç­‰" and len(clause_content) > 30:
                                clauses[clause_num] = clause_content
                            elif precision == "å®½æ¾" and len(clause_content) > 20:
                                clauses[clause_num] = clause_content
                    
                    # è¾¾åˆ°æœ€å¤§æ¡æ¬¾æ•°åˆ™åœæ­¢
                    if 0 < max_clauses <= len(clauses):
                        break
            
            # å¦‚æœä¸»è¦æ¨¡å¼æå–ä¸è¶³ï¼Œå°è¯•è¾…åŠ©æ¨¡å¼
            if not clauses or len(clauses) < 5:
                st.markdown('<p class="parse-info">å°è¯•å…¶ä»–æ¡æ¬¾æ ¼å¼æå–...</p>', unsafe_allow_html=True)
                
                # è¾…åŠ©æ¨¡å¼1ï¼šæ•°å­—ç¼–å· (1., 1.1, 1.1.1ç­‰)
                alt_patterns = [
                    re.compile(r'(\d+\.\d+\.\d+\s+.*?)(?=\d+\.\d+\.\d+\s+|$)', re.DOTALL),  # ä¸‰çº§
                    re.compile(r'(\d+\.\d+\s+.*?)(?=\d+\.\d+\s+|$)', re.DOTALL),          # äºŒçº§
                    re.compile(r'(\d+\s+.*?)(?=\d+\s+|$)', re.DOTALL)                     # ä¸€çº§
                ]
                
                for pattern in alt_patterns:
                    alt_matches = pattern.findall(full_text)
                    if alt_matches and len(alt_matches) > len(clauses):
                        for i, match in enumerate(alt_matches):
                            match = match.strip()
                            if match:
                                # ç§»é™¤é¡µç æ ‡è®°
                                clean_match = re.sub(r'\[\[PAGE \d+\]\]', '', match)
                                # æå–æ•°å­—ç¼–å·
                                num_match = re.search(r'^(\d+(\.\d+)*)', clean_match)
                                if num_match:
                                    clause_num = num_match.group(1)
                                    clause_content = re.sub(r'^\d+(\.\d+)*\s*', '', clean_match).strip()
                                else:
                                    clause_num = str(i+1)
                                    clause_content = clean_match
                                
                                if clause_content:
                                    clauses[clause_num] = clause_content
                                
                                # è¾¾åˆ°æœ€å¤§æ¡æ¬¾æ•°åˆ™åœæ­¢
                                if 0 < max_clauses <= len(clauses):
                                    break
                        if clauses:
                            break
            
            # æœ€ç»ˆè¿‡æ»¤å’Œæ•´ç†
            final_clauses = {}
            for num, content in clauses.items():
                # ç§»é™¤å¤šä½™ç©ºç™½å’Œæ¸…ç†å†…å®¹
                cleaned = re.sub(r'\s+', ' ', content).strip()
                if len(cleaned) > 20:  # ç¡®ä¿æ¡æ¬¾æœ‰è¶³å¤Ÿå†…å®¹
                    final_clauses[num] = cleaned
            
            # é™åˆ¶æœ€å¤§æ¡æ¬¾æ•°
            if 0 < max_clauses < len(final_clauses):
                final_clauses = dict(list(final_clauses.items())[:max_clauses])
            
            st.success(f"å…±è§£æ {total_pages} é¡µï¼ŒæˆåŠŸæå– {len(final_clauses)} æ¡æ¡æ¬¾")
            return final_clauses
            
    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
        return {}

# è°ƒç”¨Qwen APIè¿›è¡Œæ¡æ¬¾æ¯”å¯¹åˆ†æ
def call_qwen_api(prompt, api_key, model="qwen-turbo"):
    """è°ƒç”¨Qwen APIè¿›è¡Œæ¡æ¬¾æ¯”å¯¹åˆ†æ"""
    if not api_key:
        st.error("è¯·å…ˆé…ç½®APIå¯†é’¥")
        return None
    
    try:
        with st.spinner("æ­£åœ¨åˆ†ææ¡æ¬¾..."):
            url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": model,
                "input": {
                    "prompt": prompt
                },
                "parameters": {
                    "temperature": 0.5,
                    "top_p": 0.9,
                    "max_tokens": 800
                }
            }
            
            response = requests.post(url, headers=headers, data=json.dumps(data))
            response_data = response.json()
            
            if response.status_code == 200 and "output" in response_data:
                return response_data["output"]["text"]
            else:
                st.error(f"APIè°ƒç”¨å¤±è´¥: {response_data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return None
                
    except Exception as e:
        st.error(f"APIè¯·æ±‚é”™è¯¯: {str(e)}")
        return None

# åˆè§„æ€§åˆ†æå‡½æ•° - æŒ‰æ¡æ¬¾åŒ¹é…
def analyze_clause_matches(target_clauses, compare_clauses, api_key, model):
    """æŒ‰æ¡æ¬¾åŒ¹é…è¿›è¡Œåˆè§„æ€§åˆ†æï¼Œåªåˆ†æåŒ¹é…çš„æ¡æ¬¾"""
    if not target_clauses or not compare_clauses:
        st.warning("ç¼ºå°‘æ¡æ¬¾å†…å®¹ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return None, None
    
    # æ‰¾åˆ°åŒ¹é…çš„æ¡æ¬¾ï¼ˆæ¡æ¬¾å·ç›¸åŒï¼‰
    matched_clause_nums = [num for num in target_clauses if num in compare_clauses]
    
    if not matched_clause_nums:
        st.info("æœªæ‰¾åˆ°åŒ¹é…çš„æ¡æ¬¾")
        return {}, "æœªæ‰¾åˆ°åŒ¹é…çš„æ¡æ¬¾ï¼Œæ— æ³•è¿›è¡Œåˆè§„æ€§åˆ†æã€‚"
    
    # åˆ†ææ¯ä¸ªåŒ¹é…çš„æ¡æ¬¾
    matched_results = {}
    for clause_num in matched_clause_nums:
        target_content = target_clauses[clause_num]
        compare_content = compare_clauses[clause_num]
        
        # ç”Ÿæˆæ¡æ¬¾æ¯”å¯¹æç¤º
        prompt = f"""
        è¯·æ¯”å¯¹ä»¥ä¸‹ä¸¤æ¡æ”¿ç­–æ¡æ¬¾çš„åˆè§„æ€§å’Œå·®å¼‚ï¼š
        
        ç›®æ ‡æ¡æ¬¾ï¼ˆç¬¬{clause_num}æ¡ï¼‰ï¼š
        {target_content[:300]}
        
        å¾…æ¯”å¯¹æ¡æ¬¾ï¼ˆç¬¬{clause_num}æ¡ï¼‰ï¼š
        {compare_content[:300]}
        
        åˆ†æè¦æ±‚ï¼š
        1. åˆ¤æ–­å¾…æ¯”å¯¹æ¡æ¬¾æ˜¯å¦ç¬¦åˆç›®æ ‡æ¡æ¬¾è¦æ±‚
        2. æŒ‡å‡ºä¸¤è€…çš„ä¸»è¦å·®å¼‚ç‚¹ï¼ˆå¦‚æ— å·®å¼‚åˆ™è¯´æ˜ä¸€è‡´ï¼‰
        3. åˆ†æå·®å¼‚å¯èƒ½å¸¦æ¥çš„å½±å“
        4. ç”¨ç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡300å­—ï¼‰è¾“å‡ºåˆ†æç»“æœ
        """
        
        # è°ƒç”¨APIåˆ†æ
        result = call_qwen_api(prompt, api_key, model)
        if result:
            matched_results[clause_num] = {
                "target": target_content,
                "compare": compare_content,
                "analysis": result
            }
    
    # ç”Ÿæˆæ€»ä½“æ€»ç»“
    summary_prompt = f"""
    ä»¥ä¸‹æ˜¯ç›®æ ‡æ”¿ç­–æ–‡ä»¶ä¸å¾…æ¯”å¯¹æ–‡ä»¶ä¸­åŒ¹é…æ¡æ¬¾çš„åˆ†æç»“æœï¼š
    {json.dumps(matched_results, ensure_ascii=False, indent=2)}
    
    è¯·åŸºäºä»¥ä¸Šåˆ†æï¼Œç”¨ç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡300å­—ï¼‰æ€»ç»“ï¼š
    1. æ€»ä½“åˆè§„æ€§æƒ…å†µ
    2. ä¸»è¦å·®å¼‚ç‚¹æ±‡æ€»
    3. ç®€è¦çš„åˆè§„å»ºè®®
    """
    
    summary = call_qwen_api(summary_prompt, api_key, model) or "æ— æ³•ç”Ÿæˆæ€»ç»“ï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚"
    
    return matched_results, summary

# ç”ŸæˆWordæ–‡æ¡£
def generate_word_document(matched_results, summary, target_filename, compare_filename):
    """ç”ŸæˆWordæ ¼å¼åˆ†ææŠ¥å‘Š"""
    try:
        doc = Document()
        
        # æ ‡é¢˜
        title = doc.add_heading("æ”¿ç­–æ–‡ä»¶æ¡æ¬¾æ¯”å¯¹åˆ†ææŠ¥å‘Š", 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # åŸºæœ¬ä¿¡æ¯
        doc.add_paragraph(f"ç›®æ ‡æ”¿ç­–æ–‡ä»¶: {target_filename}")
        doc.add_paragraph(f"å¾…æ¯”å¯¹æ–‡ä»¶: {compare_filename}")
        doc.add_paragraph(f"åˆ†ææ—¥æœŸ: {time.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        doc.add_paragraph("")
        
        # æ€»ä½“æ€»ç»“
        doc.add_heading("ä¸€ã€æ€»ä½“æ€»ç»“", level=1)
        for para in re.split(r'\n+', summary):
            if para.strip():
                doc.add_paragraph(para.strip())
        
        # åŒ¹é…æ¡æ¬¾åˆ†æ
        doc.add_heading("äºŒã€åŒ¹é…æ¡æ¬¾è¯¦ç»†åˆ†æ", level=1)
        
        for clause_num, details in matched_results.items():
            doc.add_heading(f"ç¬¬{clause_num}æ¡", level=2)
            
            p = doc.add_paragraph("ç›®æ ‡æ¡æ¬¾å†…å®¹ï¼š")
            p.style = 'Heading 3'
            doc.add_paragraph(details["target"])
            
            p = doc.add_paragraph("å¾…æ¯”å¯¹æ¡æ¬¾å†…å®¹ï¼š")
            p.style = 'Heading 3'
            doc.add_paragraph(details["compare"])
            
            p = doc.add_paragraph("åˆ†æç»“æœï¼š")
            p.style = 'Heading 3'
            for para in re.split(r'\n+', details["analysis"]):
                if para.strip():
                    doc.add_paragraph(para.strip())
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
            doc.save(tmp.name)
            return tmp.name
            
    except Exception as e:
        st.error(f"ç”ŸæˆWordæ–‡æ¡£å¤±è´¥: {str(e)}")
        return None

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 2], gap="large")

with col1:
    st.subheader("ç›®æ ‡æ”¿ç­–æ–‡ä»¶")
    st.caption("ä½œä¸ºåŸºå‡†çš„æ”¿ç­–æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«å¹¶æ‹†åˆ†æ¡æ¬¾")
    target_file = st.file_uploader("ä¸Šä¼ ç›®æ ‡æ”¿ç­–æ–‡ä»¶ (PDF)", type="pdf", key="target")
    
    if target_file:
        # è§£æç›®æ ‡æ–‡ä»¶æ¡æ¬¾
        st.session_state.target_clauses = parse_pdf_by_clauses(
            target_file, 
            max_clauses=st.session_state.max_clauses,
            precision=st.session_state.parse_precision
        )
        
        with st.expander(f"æŸ¥çœ‹æå–çš„æ¡æ¬¾ (å…± {len(st.session_state.target_clauses)} æ¡)"):
            for num, content in st.session_state.target_clauses.items():
                display_text = content[:150] + "..." if len(content) > 150 else content
                st.markdown(f'<div class="clause-item"><strong>ç¬¬{num}æ¡:</strong> {display_text}</div>', unsafe_allow_html=True)
    
    # å¤šæ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("å¾…æ¯”å¯¹æ–‡ä»¶")
    st.caption("å¯ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ‹†åˆ†æ¡æ¬¾å¹¶æŒ‰ç¼–å·åŒ¹é…")
    compare_files = st.file_uploader(
        "ä¸Šä¼ å¾…æ¯”å¯¹æ–‡ä»¶ (PDF)", 
        type="pdf", 
        key="compare",
        accept_multiple_files=True
    )
    
    # å¤„ç†ä¸Šä¼ çš„å¤šä¸ªæ–‡ä»¶
    if compare_files:
        for file in compare_files:
            if file.name not in st.session_state.compare_files:
                # è§£æå¾…æ¯”å¯¹æ–‡ä»¶æ¡æ¬¾
                clauses = parse_pdf_by_clauses(
                    file, 
                    max_clauses=st.session_state.max_clauses,
                    precision=st.session_state.parse_precision
                )
                # ç¡®ä¿æ–°æ–‡ä»¶çš„å­—å…¸ç»“æ„å®Œæ•´
                st.session_state.compare_files[file.name] = {
                    "clauses": clauses,
                    "matched_results": None,
                    "summary": None
                }
                st.success(f"âœ… å·²æ·»åŠ  {file.name}ï¼Œæå–åˆ° {len(clauses)} æ¡æ¡æ¬¾")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„å¾…æ¯”å¯¹æ–‡ä»¶åˆ—è¡¨
    if st.session_state.compare_files:
        st.subheader("å·²ä¸Šä¼ æ–‡ä»¶")
        for filename in st.session_state.compare_files.keys():
            col_a, col_b = st.columns([3, 1])
            with col_a:
                clause_count = len(st.session_state.compare_files[filename]["clauses"])
                st.markdown(f"- {filename} (æ¡æ¬¾æ•°: {clause_count})")
            with col_b:
                if st.button("åˆ†æ", key=f"analyze_{filename}") and st.session_state.target_clauses:
                    # è¿›è¡Œæ¡æ¬¾åŒ¹é…åˆ†æ
                    matched_results, summary = analyze_clause_matches(
                        st.session_state.target_clauses,
                        st.session_state.compare_files[filename]["clauses"],
                        st.session_state.api_key,
                        model_option
                    )
                    if matched_results is not None:
                        st.session_state.compare_files[filename]["matched_results"] = matched_results
                        st.session_state.compare_files[filename]["summary"] = summary
                        st.session_state.current_file = filename
                        st.success(f"âœ… {filename} åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(matched_results)} æ¡åŒ¹é…æ¡æ¬¾")

with col2:
    st.subheader("åˆ†æç»“æœ")
    
    # æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©æ ‡ç­¾
    if st.session_state.compare_files:
        st.markdown("**é€‰æ‹©æ–‡ä»¶æŸ¥çœ‹ç»“æœï¼š**")
        cols_per_row = 3
        files = list(st.session_state.compare_files.items())
        rows = (len(files) + cols_per_row - 1) // cols_per_row
        
        for row in range(rows):
            cols = st.columns(cols_per_row)
            for col_idx in range(cols_per_row):
                file_idx = row * cols_per_row + col_idx
                if file_idx < len(files):
                    filename, data = files[file_idx]
                    with cols[col_idx]:
                        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿matched_resultså­˜åœ¨ä¸”ä¸ä¸ºNone
                        if "matched_results" in data and data["matched_results"]:
                            match_count = len(data["matched_results"])
                            status = f" ({match_count}æ¡åŒ¹é…)"
                        else:
                            status = ""
                        
                        if st.button(f"{filename.split('.')[0]}{status}", key=f"tab_{filename}"):
                            st.session_state.current_file = filename
    
    # æ˜¾ç¤ºå½“å‰é€‰ä¸­æ–‡ä»¶çš„åˆ†æç»“æœ
    if st.session_state.current_file:
        filename = st.session_state.current_file
        # ç¡®ä¿æ–‡ä»¶æ•°æ®å­˜åœ¨
        if filename in st.session_state.compare_files:
            file_data = st.session_state.compare_files[filename]
            # å®‰å…¨è·å–åŒ¹é…ç»“æœå’Œæ€»ç»“
            matched_results = file_data.get("matched_results", None)
            summary = file_data.get("summary", "")
            
            if matched_results is not None:
                # æ˜¾ç¤ºæ€»ä½“æ€»ç»“
                st.markdown("### ğŸ“Š æ€»ä½“åˆ†ææ€»ç»“")
                st.markdown('<div class="summary-box">', unsafe_allow_html=True)
                for para in re.split(r'\n+', summary):
                    if para.strip():
                        st.markdown(f"{para.strip()}  \n")
                st.markdown('</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºåŒ¹é…æ¡æ¬¾çš„è¯¦ç»†åˆ†æ
                if matched_results:
                    st.markdown(f"### ğŸ” åŒ¹é…æ¡æ¬¾è¯¦æƒ… ({len(matched_results)} æ¡)")
                    
                    for clause_num, details in matched_results.items():
                        st.markdown(f'#### ç¬¬{clause_num}æ¡')
                        st.markdown('<div class="matched-clause">', unsafe_allow_html=True)
                        
                        st.markdown("**ç›®æ ‡æ¡æ¬¾å†…å®¹ï¼š**")
                        st.write(details["target"][:500] + "..." if len(details["target"]) > 500 else details["target"])
                        
                        st.markdown("**å¾…æ¯”å¯¹æ¡æ¬¾å†…å®¹ï¼š**")
                        st.write(details["compare"][:500] + "..." if len(details["compare"]) > 500 else details["compare"])
                        
                        st.markdown('<div class="difference-section">', unsafe_allow_html=True)
                        st.markdown("**åˆ†æç»“æœï¼š**")
                        for para in re.split(r'\n+', details["analysis"]):
                            if para.strip():
                                st.markdown(f"{para.strip()}  \n")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        st.markdown('</div>', unsafe_allow_html=True)
                
                # ç”Ÿæˆå¹¶ä¸‹è½½Wordæ–‡æ¡£
                if target_file and matched_results is not None:
                    word_file = generate_word_document(
                        matched_results,
                        summary,
                        target_file.name,
                        filename
                    )
                    
                    if word_file:
                        with open(word_file, "rb") as f:
                            st.download_button(
                                label=f"ğŸ’¾ ä¸‹è½½ {filename} çš„åˆ†ææŠ¥å‘Š",
                                data=f,
                                file_name=f"æ”¿ç­–æ¡æ¬¾æ¯”å¯¹æŠ¥å‘Š_{filename}_{time.strftime('%Y%m%d')}.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                        os.unlink(word_file)
            else:
                st.info("è¯·ç‚¹å‡»æ–‡ä»¶æ—çš„'åˆ†æ'æŒ‰é’®ç”Ÿæˆåˆ†æç»“æœ")
        else:
            st.warning("æ‰€é€‰æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©")
    else:
        st.info("è¯·ä¸Šä¼ å¾…æ¯”å¯¹æ–‡ä»¶å¹¶é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶æŸ¥çœ‹åˆ†æç»“æœ")

# å¸®åŠ©ä¿¡æ¯
with st.expander("â„¹ï¸ ä½¿ç”¨å¸®åŠ©"):
    st.markdown("""
    ### æ¡æ¬¾è§£æè¯´æ˜
    ç³»ç»Ÿé‡‡ç”¨å¤šå±‚æ¬¡æ¡æ¬¾è¯†åˆ«æœºåˆ¶ï¼š
    1. ä¼˜å…ˆè¯†åˆ«"ç¬¬Xæ¡"æ ¼å¼çš„æ ‡å‡†æ¡æ¬¾
    2. å¦‚è¯†åˆ«ä¸è¶³ï¼Œè‡ªåŠ¨å°è¯•æ•°å­—ç¼–å·æ ¼å¼(1., 1.1ç­‰)
    3. å¯é€šè¿‡ä¾§è¾¹æ è°ƒæ•´è§£æç²¾åº¦ï¼š
       - å®½æ¾ï¼šæå–æ›´å¤šå¯èƒ½çš„æ¡æ¬¾ï¼Œé€‚åˆæ ¼å¼ä¸è§„èŒƒçš„æ–‡ä»¶
       - ä¸­ç­‰ï¼šå¹³è¡¡æå–æ•°é‡å’Œå‡†ç¡®æ€§ï¼ˆé»˜è®¤ï¼‰
       - ä¸¥æ ¼ï¼šåªæå–æ˜ç¡®ç¬¦åˆæ ¼å¼çš„æ¡æ¬¾ï¼Œé€‚åˆè§„èŒƒæ–‡ä»¶
    
    ### ä½¿ç”¨æµç¨‹
    1. ä¸Šä¼ ç›®æ ‡æ”¿ç­–æ–‡ä»¶å’Œå¾…æ¯”å¯¹æ–‡ä»¶
    2. å¯åœ¨ä¾§è¾¹æ è°ƒæ•´æ¡æ¬¾æå–å‚æ•°
    3. ç‚¹å‡»"åˆ†æ"æŒ‰é’®è¿›è¡Œæ¡æ¬¾åŒ¹é…ä¸åˆ†æ
    4. æŸ¥çœ‹æ€»ä½“æ€»ç»“å’ŒåŒ¹é…æ¡æ¬¾çš„è¯¦ç»†åˆ†æ
    5. ä¸‹è½½Wordæ ¼å¼æŠ¥å‘Šï¼ˆå¯é€‰ï¼‰
    
    ### æé«˜è§£ææ•ˆæœçš„å»ºè®®
    - ç¡®ä¿PDFæ–‡ä»¶ä¸ºå¯å¤åˆ¶æ–‡æœ¬ï¼ˆéå›¾ç‰‡æ‰«æä»¶ï¼‰
    - æ¡æ¬¾ç¼–å·æ¸…æ™°çš„æ–‡ä»¶è§£ææ•ˆæœæ›´ä½³
    - å¦‚æå–æ¡æ¬¾ä¸è¶³ï¼Œå°è¯•è°ƒæ•´ä¸º"å®½æ¾"è§£æç²¾åº¦
    - è¿‡é•¿æ–‡ä»¶å¯é€‚å½“å¢åŠ æœ€å¤§æ¡æ¬¾æ•°é‡é™åˆ¶
    """)
    
