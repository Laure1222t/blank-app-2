import streamlit as st
import fitz  # PyMuPDF
import re
import time
import requests
import json
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import tempfile
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¤šæ–‡ä»¶æ”¿ç­–æ¯”å¯¹åˆ†æå·¥å…·",
    page_icon="ğŸ“œ",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .stButton>button {
        margin-top: 1rem;
    }
    .analysis-box {
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 1rem;
        margin-top: 1rem;
        background-color: #f9f9f9;
    }
    .file-tab {
        padding: 0.5rem 1rem;
        border-radius: 4px;
        margin: 0.25rem;
        cursor: pointer;
        display: inline-block;
    }
    .file-tab.active {
        background-color: #007bff;
        color: white;
    }
    .file-tab.inactive {
        background-color: #e9ecef;
        color: #495057;
    }
    .clause-item {
        padding: 0.5rem;
        margin: 0.25rem 0;
        border-radius: 3px;
        background-color: #f0f2f6;
    }
    .parse-status {
        font-size: 0.9rem;
        color: #6c757d;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'target_clauses' not in st.session_state:
    st.session_state.target_clauses = []
if 'compare_files' not in st.session_state:
    st.session_state.compare_files = {}  # {æ–‡ä»¶å: {æ¡æ¬¾: [], åˆ†æç»“æœ: ""}}
if 'current_file' not in st.session_state:
    st.session_state.current_file = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = os.getenv("QWEN_API_KEY", "")
if 'max_clauses' not in st.session_state:
    st.session_state.max_clauses = 30  # é»˜è®¤æœ€å¤§æ¡æ¬¾æ•°
if 'parse_method' not in st.session_state:
    st.session_state.parse_method = "æ™ºèƒ½è¯†åˆ«"  # è§£ææ–¹æ³•

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“œ å¤šæ–‡ä»¶æ”¿ç­–æ¯”å¯¹åˆ†æå·¥å…·")
st.markdown("ä¸Šä¼ ç›®æ ‡æ”¿ç­–æ–‡ä»¶å’Œå¤šä¸ªå¾…æ¯”å¯¹æ–‡ä»¶ï¼Œç³»ç»Ÿå°†é€ä¸€è¿›è¡Œæ¡æ¬¾æ¯”å¯¹ä¸åˆè§„æ€§åˆ†æ")
st.markdown("---")

# æ¡æ¬¾æå–è®¾ç½®
st.sidebar.subheader("æ¡æ¬¾æå–è®¾ç½®")
st.session_state.max_clauses = st.sidebar.slider(
    "æœ€å¤§æ¡æ¬¾æ•°é‡", 
    min_value=0, 
    max_value=50, 
    value=st.session_state.max_clauses,
    help="è®¾ç½®ä»æ–‡ä»¶ä¸­æå–çš„æœ€å¤§æ¡æ¬¾æ•°é‡ï¼Œ0è¡¨ç¤ºæ— é™åˆ¶ï¼ˆæœ€å¤š50æ¡ï¼‰"
)

# æ¡æ¬¾æ‹†åˆ†ç²¾ç»†åº¦è®¾ç½®
clause_precision = st.sidebar.select_slider(
    "æ¡æ¬¾æ‹†åˆ†ç²¾ç»†åº¦",
    options=["ç²—ç•¥", "ä¸­ç­‰", "ç²¾ç»†"],
    value="ä¸­ç­‰",
    help="è®¾ç½®æ¡æ¬¾æ‹†åˆ†çš„ç²¾ç»†ç¨‹åº¦ï¼Œç²¾ç»†æ¨¡å¼ä¼šè¯†åˆ«æ›´å¤šå­æ¡æ¬¾"
)

# è§£ææ–¹æ³•é€‰æ‹©
st.session_state.parse_method = st.sidebar.radio(
    "è§£ææ–¹æ³•",
    ["æ™ºèƒ½è¯†åˆ«", "æŒ‰æ ‡é¢˜å±‚çº§", "æŒ‰æ®µè½æ‹†åˆ†"],
    help="å½“æ™ºèƒ½è¯†åˆ«æ•ˆæœä¸ä½³æ—¶ï¼Œå¯å°è¯•å…¶ä»–è§£ææ–¹æ³•"
)

# APIé…ç½®
with st.expander("ğŸ”‘ API é…ç½®", expanded=not st.session_state.api_key):
    st.session_state.api_key = st.text_input("è¯·è¾“å…¥Qwen APIå¯†é’¥", value=st.session_state.api_key, type="password")
    model_option = st.selectbox(
        "é€‰æ‹©Qwenæ¨¡å‹",
        ["qwen-turbo", "qwen-plus", "qwen-max"],
        index=0  # é»˜è®¤ä½¿ç”¨è½»é‡ç‰ˆ
    )
    st.caption("æç¤ºï¼šå¯ä»é˜¿é‡Œäº‘DashScopeå¹³å°è·å–APIå¯†é’¥ï¼Œä¸åŒæ¨¡å‹èƒ½åŠ›å’Œæˆæœ¬ä¸åŒ")

# ä¼˜åŒ–çš„PDFè§£æå‡½æ•° - è§£å†³è§£æä¸å®Œå…¨é—®é¢˜
def parse_pdf(file, max_clauses=30, precision="ä¸­ç­‰", method="æ™ºèƒ½è¯†åˆ«"):
    """è§£æPDFæ–‡ä»¶å¹¶æå–ç»“æ„åŒ–æ¡æ¬¾ï¼Œä¼˜åŒ–è§£æå®Œæ•´æ€§"""
    try:
        with st.spinner("æ­£åœ¨è§£ææ–‡ä»¶..."):
            doc = fitz.open(stream=file.read(), filetype="pdf")
            total_pages = len(doc)
            text = ""
            page_texts = []  # å­˜å‚¨æ¯é¡µçš„æ–‡æœ¬ï¼Œç”¨äºå¤„ç†è·¨é¡µæ¡æ¬¾
            
            # é€é¡µè¯»å–æ–‡æœ¬ï¼Œä¿ç•™é¡µé¢åˆ†éš”ä¿¡æ¯
            for page_num, page in enumerate(doc, 1):
                page_text = page.get_text()
                page_texts.append(f"[[PAGE {page_num}]]\n{page_text}")
                text += page_text + "\n\n"
            
            # æ–‡æœ¬é¢„å¤„ç† - å¢å¼ºç‰ˆ
            text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)  # ç§»é™¤æ§åˆ¶å­—ç¬¦
            text = re.sub(r'(\r\n|\r|\n)+', '\n', text)  # ç»Ÿä¸€æ¢è¡Œç¬¦
            text = re.sub(r'[^\S\n]+', ' ', text)  # æ›¿æ¢éæ¢è¡Œçš„ç©ºç™½å­—ç¬¦ä¸ºç©ºæ ¼
            text = text.strip()
            
            # æ ¹æ®é€‰æ‹©çš„è§£ææ–¹æ³•å¤„ç†
            clauses = []
            
            if method == "æ™ºèƒ½è¯†åˆ«":
                # æ™ºèƒ½è¯†åˆ«æ¨¡å¼ - å°è¯•å¤šç§æ¨¡å¼
                clauses = parse_with_patterns(text, precision)
                # å¦‚æœæå–çš„æ¡æ¬¾å¤ªå°‘ï¼Œå°è¯•å…¶ä»–æ¨¡å¼è¡¥å……
                if len(clauses) < 5:
                    st.markdown('<p class="parse-status">æ™ºèƒ½è¯†åˆ«æå–æ¡æ¬¾è¾ƒå°‘ï¼Œå°è¯•è¡¥å……æå–...</p>', unsafe_allow_html=True)
                    heading_clauses = parse_by_headings(text)
                    # åˆå¹¶æ¡æ¬¾å¹¶å»é‡
                    combined = list(clauses)
                    for clause in heading_clauses:
                        if clause not in combined:
                            combined.append(clause)
                    clauses = combined
            
            elif method == "æŒ‰æ ‡é¢˜å±‚çº§":
                # æŒ‰æ ‡é¢˜å±‚çº§è§£æ
                clauses = parse_by_headings(text)
            
            else:  # æŒ‰æ®µè½æ‹†åˆ†
                # æŒ‰æ®µè½æ‹†åˆ†æ¨¡å¼
                clauses = parse_by_paragraphs(text)
            
            # åå¤„ç†ï¼šè¿‡æ»¤è¿‡çŸ­æ¡æ¬¾å’Œç©ºç™½æ¡æ¬¾
            clauses = [clause.strip() for clause in clauses if clause.strip() and len(clause.strip()) > 30]
            
            # å¤„ç†è·¨é¡µæ¡æ¬¾ï¼ˆç®€å•åˆå¹¶å¯èƒ½è¢«åˆ†é¡µç¬¦åˆ†å‰²çš„æ¡æ¬¾ï¼‰
            if len(clauses) > 1:
                merged_clauses = []
                i = 0
                while i < len(clauses):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«é¡µç æ ‡è®°ï¼Œä¸”ä¸æ˜¯æœ€åä¸€æ¡
                    if "[[PAGE" in clauses[i] and i < len(clauses) - 1:
                        # åˆå¹¶å½“å‰æ¡æ¬¾å’Œä¸‹ä¸€æ¡æ¬¾
                        merged = clauses[i] + " " + clauses[i+1]
                        merged = re.sub(r'\[\[PAGE \d+\]\]', '', merged)  # ç§»é™¤é¡µç æ ‡è®°
                        merged_clauses.append(merged)
                        i += 2  # è·³è¿‡ä¸‹ä¸€æ¡
                    else:
                        # ç§»é™¤é¡µç æ ‡è®°
                        clean_clause = re.sub(r'\[\[PAGE \d+\]\]', '', clauses[i])
                        merged_clauses.append(clean_clause)
                        i += 1
                clauses = merged_clauses
            
            # åº”ç”¨æœ€å¤§æ¡æ¬¾æ•°é™åˆ¶
            max_clauses = min(max_clauses, 50) if max_clauses > 0 else 50
            final_clauses = clauses[:max_clauses]
            
            # æ˜¾ç¤ºè§£æçŠ¶æ€
            st.markdown(f'<p class="parse-status">å…±è§£æ {total_pages} é¡µï¼Œæå– {len(final_clauses)} æ¡æœ‰æ•ˆæ¡æ¬¾</p>', unsafe_allow_html=True)
            return final_clauses
            
    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
        return []

# æŒ‰æ¨¡å¼è¯†åˆ«æ¡æ¬¾
def parse_with_patterns(text, precision):
    # æ ¹æ®ç²¾ç»†åº¦é€‰æ‹©ä¸åŒçš„æ¡æ¬¾æå–æ¨¡å¼
    patterns = []
    
    if precision == "ç²¾ç»†":
        # ç²¾ç»†æ¨¡å¼ï¼šè¯†åˆ«æ›´å¤šç±»å‹çš„æ¡æ¬¾
        patterns = [
            # æ•°å­—ç¼–å·æ¡æ¬¾ï¼ˆæ”¯æŒå¤šçº§ï¼‰
            re.compile(r'(\d+\.\d+\.\d+\.\d+\s+.*?)(?=\d+\.\d+\.\d+\.\d+\s+|$)', re.DOTALL),  # å››çº§
            re.compile(r'(\d+\.\d+\.\d+\s+.*?)(?=\d+\.\d+\.\d+\s+|$)', re.DOTALL),          # ä¸‰çº§
            re.compile(r'(\d+\.\d+\s+.*?)(?=\d+\.\d+\s+|$)', re.DOTALL),                  # äºŒçº§
            re.compile(r'(\d+\s+.*?)(?=\d+\s+|$)', re.DOTALL),                            # ä¸€çº§
            
            # ä¸­æ–‡ç¼–å·æ¡æ¬¾
            re.compile(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+\.\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+\.\s+|$)', re.DOTALL),  # ä¸­æ–‡æ•°å­—
            re.compile(r'(\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]\)\s+.*?)(?=\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]\)\s+|$)', re.DOTALL),  # å¸¦æ‹¬å·ä¸­æ–‡
            re.compile(r'([ç”²ä¹™ä¸™ä¸æˆŠå·±åºšè¾›å£¬ç™¸]+\.\s+.*?)(?=[ç”²ä¹™ä¸™ä¸æˆŠå·±åºšè¾›å£¬ç™¸]+\.\s+|$)', re.DOTALL),  # å¤©å¹²
            
            # å­—æ¯ç¼–å·æ¡æ¬¾
            re.compile(r'([A-Z]\.\s+.*?)(?=[A-Z]\.\s+|$)', re.DOTALL),                    # å¤§å†™å­—æ¯
            re.compile(r'([a-z]\.\s+.*?)(?=[a-z]\.\s+|$)', re.DOTALL),                    # å°å†™å­—æ¯
            re.compile(r'(\([A-Za-z]\)\s+.*?)(?=\([A-Za-z]\)\s+|$)', re.DOTALL)           # å¸¦æ‹¬å·å­—æ¯
        ]
    elif precision == "ä¸­ç­‰":
        # ä¸­ç­‰æ¨¡å¼ï¼šè¯†åˆ«ä¸»è¦å±‚çº§æ¡æ¬¾
        patterns = [
            re.compile(r'(\d+\.\d+\.\d+\s+.*?)(?=\d+\.\d+\.\d+\s+|$)', re.DOTALL),          # ä¸‰çº§
            re.compile(r'(\d+\.\d+\s+.*?)(?=\d+\.\d+\s+|$)', re.DOTALL),                  # äºŒçº§
            re.compile(r'(\d+\s+.*?)(?=\d+\s+|$)', re.DOTALL),                            # ä¸€çº§
            re.compile(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\.\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\.\s+|$)', re.DOTALL),  # ä¸­æ–‡æ•°å­—
            re.compile(r'([A-Z]\.\s+.*?)(?=[A-Z]\.\s+|$)', re.DOTALL)                     # å¤§å†™å­—æ¯
        ]
    else:  # ç²—ç•¥
        # ç²—ç•¥æ¨¡å¼ï¼šåªè¯†åˆ«ä¸»è¦æ¡æ¬¾
        patterns = [
            re.compile(r'(\d+\.\d+\s+.*?)(?=\d+\.\d+\s+|$)', re.DOTALL),                  # äºŒçº§
            re.compile(r'(\d+\s+.*?)(?=\d+\s+|$)', re.DOTALL),                            # ä¸€çº§
            re.compile(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\.\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\.\s+|$)', re.DOTALL)   # ä¸­æ–‡æ•°å­—
        ]
    
    clauses = []
    for pattern in patterns:
        matches = pattern.findall(text)
        if matches:
            # è¿‡æ»¤è¿‡çŸ­çš„æ¡æ¬¾
            clauses = [match.strip() for match in matches if len(match.strip()) > 20]
            break
    
    return clauses

# æŒ‰æ ‡é¢˜å±‚çº§è§£æ
def parse_by_headings(text):
    # åŒ¹é…å¸¸è§çš„æ ‡é¢˜æ ¼å¼
    heading_patterns = [
        re.compile(r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+ç« \s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+ç« \s+|$)', re.DOTALL),  # ç« èŠ‚
        re.compile(r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+|$)', re.DOTALL),  # æ¡
        re.compile(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\ã€\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\ã€\s+|$)', re.DOTALL),        # ä¸­æ–‡åºå·åŠ é¡¿å·
    ]
    
    for pattern in heading_patterns:
        matches = pattern.findall(text)
        if matches and len(matches) > 1:
            return [match.strip() for match in matches]
    
    # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨é€šç”¨æ¨¡å¼
    return re.split(r'(?<=[ã€‚ï¼›ï¼ï¼Ÿ])\s+', text)

# æŒ‰æ®µè½æ‹†åˆ†
def parse_by_paragraphs(text):
    # ä½¿ç”¨å¤šç§æ ‡ç‚¹ç¬¦å·ä½œä¸ºæ®µè½åˆ†éš”ç¬¦
    separators = r'ã€‚(?=\s+)|ï¼(?=\s+)|ï¼Ÿ(?=\s+)|ï¼›(?=\s+)|[\n]{2,}'
    paragraphs = re.split(separators, text)
    # è¿‡æ»¤è¿‡çŸ­æ®µè½å¹¶è¡¥å……ç»“å°¾æ ‡ç‚¹
    processed = []
    for para in paragraphs:
        para = para.strip()
        if len(para) > 50:
            if not para.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.')):
                para += 'ã€‚'
            processed.append(para)
    return processed

# è°ƒç”¨Qwen APIè¿›è¡Œåˆ†æ
def call_qwen_api(prompt, api_key, model="qwen-turbo"):
    """è°ƒç”¨Qwen APIè¿›è¡Œåˆè§„æ€§åˆ†æ"""
    if not api_key:
        st.error("è¯·å…ˆé…ç½®APIå¯†é’¥")
        return None
    
    try:
        with st.spinner("æ­£åœ¨è°ƒç”¨APIè¿›è¡Œåˆ†æ..."):
            url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": model,
                "input": {
                    "prompt": prompt
                },
                "parameters": {
                    "temperature": 0.6,
                    "top_p": 0.9,
                    "max_tokens": 1500
                }
            }
            
            response = requests.post(url, headers=headers, data=json.dumps(data))
            response_data = response.json()
            
            if response.status_code == 200 and "output" in response_data:
                return response_data["output"]["text"]
            else:
                st.error(f"APIè°ƒç”¨å¤±è´¥: {response_data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return None
                
    except Exception as e:
        st.error(f"APIè¯·æ±‚é”™è¯¯: {str(e)}")
        return None

# åˆè§„æ€§åˆ†æå‡½æ•°
def analyze_compliance(target_clauses, compare_clauses, api_key, model):
    """ç”Ÿæˆåˆ†ææç¤ºå¹¶è°ƒç”¨API"""
    if not target_clauses or not compare_clauses:
        st.warning("ç¼ºå°‘æ¡æ¬¾å†…å®¹ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return None
    
    # å‡†å¤‡æ¡æ¬¾æ–‡æœ¬
    target_text = "\n".join([f"æ¡æ¬¾{i+1}: {clause[:200]}" for i, clause in enumerate(target_clauses)])
    compare_text = "\n".join([f"æ¡æ¬¾{i+1}: {clause[:200]}" for i, clause in enumerate(compare_clauses)])
    
    # åˆ†ææç¤ºè¯
    prompt = """
    ä½ æ˜¯æ”¿ç­–åˆè§„æ€§åˆ†æä¸“å®¶ï¼Œéœ€è¦æ¯”å¯¹ä¸¤ä»½æ–‡ä»¶çš„æ¡æ¬¾å¹¶è¿›è¡Œåˆè§„æ€§åˆ†æã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ‰§è¡Œï¼š
    
    1. å…¨é¢è¦†ç›–æä¾›çš„æ‰€æœ‰æ¡æ¬¾ï¼Œä¸è¦é—æ¼é‡è¦å†…å®¹
    2. é‡ç‚¹åˆ†æåˆè§„æ€§ï¼šå¯¹äºä¸åŒä¹‹å¤„ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨å†²çªã€ä¸ä¸€è‡´æˆ–ä¸åˆè§„çš„æƒ…å†µ
    3. å¯¹äºç›¸åŒæˆ–ä¸€è‡´çš„æ¡æ¬¾ï¼Œç®€è¦è¯´æ˜å³å¯
    4. åˆ†ææ—¶è¯·åŸºäºæ¡æ¬¾å†…å®¹æœ¬èº«ï¼Œä¸è¦æ·»åŠ å¤–éƒ¨çŸ¥è¯†
    5. è¾“å‡ºæ ¼å¼ï¼š
       - å…ˆåˆ—å‡ºæ¡æ¬¾å¯¹åº”å…³ç³»
       - å†åˆ†æå·®å¼‚ç‚¹
       - æœ€åç»™å‡ºåˆè§„æ€§åˆ¤æ–­åŠå»ºè®®
    
    ç›®æ ‡æ”¿ç­–æ–‡ä»¶æ¡æ¬¾ï¼š
    {target_text}
    
    å¾…æ¯”å¯¹æ–‡ä»¶æ¡æ¬¾ï¼š
    {compare_text}
    
    è¯·ç”¨ä¸­æ–‡è¯¦ç»†è¾“å‡ºåˆ†æç»“æœï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°ã€ç»“è®ºæ˜ç¡®ã€‚
    """.format(target_text=target_text, compare_text=compare_text)
    
    return call_qwen_api(prompt, api_key, model)

# ç”ŸæˆWordæ–‡æ¡£
def generate_word_document(analysis_result, target_filename, compare_filename):
    """ç”ŸæˆWordæ ¼å¼åˆ†ææŠ¥å‘Š"""
    try:
        doc = Document()
        
        # æ ‡é¢˜
        title = doc.add_heading("æ”¿ç­–æ–‡ä»¶åˆè§„æ€§åˆ†ææŠ¥å‘Š", 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # åŸºæœ¬ä¿¡æ¯
        doc.add_paragraph(f"ç›®æ ‡æ”¿ç­–æ–‡ä»¶: {target_filename}")
        doc.add_paragraph(f"å¾…æ¯”å¯¹æ–‡ä»¶: {compare_filename}")
        doc.add_paragraph(f"åˆ†ææ—¥æœŸ: {time.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        doc.add_paragraph("")
        
        # åˆ†æç»“æœ
        doc.add_heading("ä¸€ã€åˆ†æç»“æœ", level=1)
        
        # å¤„ç†åˆ†æç»“æœä¸ºæ®µè½
        paragraphs = re.split(r'\n+', analysis_result)
        for para in paragraphs:
            para = para.strip()
            if para:
                if para.startswith(('1.', '2.', '3.')) or para.endswith('ï¼š'):
                    p = doc.add_paragraph(para)
                    p.style = 'Heading 2'
                else:
                    p = doc.add_paragraph(para)
                    p.paragraph_format.space_after = Pt(6)
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
            doc.save(tmp.name)
            return tmp.name
            
    except Exception as e:
        st.error(f"ç”ŸæˆWordæ–‡æ¡£å¤±è´¥: {str(e)}")
        return None

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 2], gap="large")

with col1:
    st.subheader("ç›®æ ‡æ”¿ç­–æ–‡ä»¶")
    st.caption("ä½œä¸ºåŸºå‡†çš„æ”¿ç­–æ–‡ä»¶")
    target_file = st.file_uploader("ä¸Šä¼ ç›®æ ‡æ”¿ç­–æ–‡ä»¶ (PDF)", type="pdf", key="target")
    
    if target_file:
        # ä½¿ç”¨å½“å‰è®¾ç½®è§£æç›®æ ‡æ–‡ä»¶
        st.session_state.target_clauses = parse_pdf(
            target_file, 
            max_clauses=st.session_state.max_clauses,
            precision=clause_precision,
            method=st.session_state.parse_method
        )
        st.success(f"âœ… è§£æå®Œæˆï¼Œæå–åˆ° {len(st.session_state.target_clauses)} æ¡æ¡æ¬¾")
        
        with st.expander(f"æŸ¥çœ‹æå–çš„æ¡æ¬¾ (å…± {len(st.session_state.target_clauses)} æ¡)"):
            for i, clause in enumerate(st.session_state.target_clauses):
                display_text = clause[:150] + "..." if len(clause) > 150 else clause
                st.markdown(f'<div class="clause-item"><strong>æ¡æ¬¾ {i+1}:</strong> {display_text}</div>', unsafe_allow_html=True)
    
    # å¤šæ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("å¾…æ¯”å¯¹æ–‡ä»¶")
    st.caption("å¯ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œå°†é€ä¸€ä¸ç›®æ ‡æ–‡ä»¶æ¯”å¯¹")
    compare_files = st.file_uploader(
        "ä¸Šä¼ å¾…æ¯”å¯¹æ–‡ä»¶ (PDF)", 
        type="pdf", 
        key="compare",
        accept_multiple_files=True
    )
    
    # å¤„ç†ä¸Šä¼ çš„å¤šä¸ªæ–‡ä»¶
    if compare_files:
        for file in compare_files:
            if file.name not in st.session_state.compare_files:
                # ä½¿ç”¨å½“å‰è®¾ç½®è§£æå¾…æ¯”å¯¹æ–‡ä»¶
                clauses = parse_pdf(
                    file, 
                    max_clauses=st.session_state.max_clauses,
                    precision=clause_precision,
                    method=st.session_state.parse_method
                )
                st.session_state.compare_files[file.name] = {
                    "clauses": clauses,
                    "analysis": None
                }
                st.success(f"âœ… å·²æ·»åŠ  {file.name}ï¼Œæå–åˆ° {len(clauses)} æ¡æ¡æ¬¾")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„å¾…æ¯”å¯¹æ–‡ä»¶åˆ—è¡¨
    if st.session_state.compare_files:
        st.subheader("å·²ä¸Šä¼ æ–‡ä»¶")
        for filename in st.session_state.compare_files.keys():
            col_a, col_b = st.columns([3, 1])
            with col_a:
                st.markdown(f"- {filename} (æ¡æ¬¾æ•°: {len(st.session_state.compare_files[filename]['clauses'])})")
            with col_b:
                if st.button("åˆ†æ", key=f"analyze_{filename}") and st.session_state.target_clauses:
                    result = analyze_compliance(
                        st.session_state.target_clauses,
                        st.session_state.compare_files[filename]["clauses"],
                        st.session_state.api_key,
                        model_option
                    )
                    if result:
                        st.session_state.compare_files[filename]["analysis"] = result
                        st.session_state.current_file = filename
                        st.success(f"âœ… {filename} åˆ†æå®Œæˆ")

with col2:
    st.subheader("åˆ†æç»“æœ")
    
    # æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©æ ‡ç­¾
    if st.session_state.compare_files:
        st.markdown("**é€‰æ‹©æ–‡ä»¶æŸ¥çœ‹ç»“æœï¼š**")
        # è®¡ç®—æ¯è¡Œæ˜¾ç¤ºçš„æ–‡ä»¶æ ‡ç­¾æ•°é‡
        cols_per_row = 3
        files = list(st.session_state.compare_files.items())
        rows = (len(files) + cols_per_row - 1) // cols_per_row
        
        for row in range(rows):
            cols = st.columns(cols_per_row)
            for col_idx in range(cols_per_row):
                file_idx = row * cols_per_row + col_idx
                if file_idx < len(files):
                    filename, data = files[file_idx]
                    with cols[col_idx]:
                        status = " âœ“" if data["analysis"] else ""
                        if st.button(f"{filename.split('.')[0]}{status}", key=f"tab_{filename}"):
                            st.session_state.current_file = filename
    
    # æ˜¾ç¤ºå½“å‰é€‰ä¸­æ–‡ä»¶çš„åˆ†æç»“æœ
    if st.session_state.current_file and st.session_state.compare_files[st.session_state.current_file]["analysis"]:
        filename = st.session_state.current_file
        analysis_result = st.session_state.compare_files[filename]["analysis"]
        
        st.markdown('<div class="analysis-box">', unsafe_allow_html=True)
        for para in re.split(r'\n+', analysis_result):
            if para.strip():
                st.markdown(f"{para.strip()}  \n")
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ç”Ÿæˆå¹¶ä¸‹è½½Wordæ–‡æ¡£
        if target_file:
            word_file = generate_word_document(
                analysis_result,
                target_file.name,
                filename
            )
            
            if word_file:
                with open(word_file, "rb") as f:
                    st.download_button(
                        label=f"ğŸ’¾ ä¸‹è½½ {filename} çš„åˆ†ææŠ¥å‘Š",
                        data=f,
                        file_name=f"æ”¿ç­–åˆè§„æ€§åˆ†ææŠ¥å‘Š_{filename}_{time.strftime('%Y%m%d')}.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                os.unlink(word_file)
    elif st.session_state.compare_files:
        st.info("è¯·é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œåˆ†æï¼Œæˆ–ç‚¹å‡»æ–‡ä»¶æ—çš„'åˆ†æ'æŒ‰é’®")
    else:
        st.info("è¯·ä¸Šä¼ å¾…æ¯”å¯¹æ–‡ä»¶")

# å¸®åŠ©ä¿¡æ¯
with st.expander("â„¹ï¸ ä½¿ç”¨å¸®åŠ©"):
    st.markdown("""
    ### æé«˜è§£æå®Œæ•´æ€§çš„æŠ€å·§
    1. **å°è¯•ä¸åŒè§£ææ–¹æ³•**ï¼š
       - æ™ºèƒ½è¯†åˆ«ï¼šè‡ªåŠ¨è¯†åˆ«å¤šç§æ¡æ¬¾æ ¼å¼ï¼ˆé»˜è®¤ï¼‰
       - æŒ‰æ ‡é¢˜å±‚çº§ï¼šä¼˜å…ˆè¯†åˆ«ç« èŠ‚ã€æ¡æ¬¾ç­‰æ ‡é¢˜ç»“æ„
       - æŒ‰æ®µè½æ‹†åˆ†ï¼šç®€å•æŒ‰æ ‡ç‚¹ç¬¦å·æ‹†åˆ†æ–‡æœ¬
    
    2. **è°ƒæ•´ç²¾ç»†åº¦**ï¼š
       - å¤æ‚æ–‡ä»¶å»ºè®®ä½¿ç”¨"ç²¾ç»†"æ¨¡å¼
       - ç»“æ„ç®€å•çš„æ–‡ä»¶å¯ä½¿ç”¨"ç²—ç•¥"æ¨¡å¼æé«˜æ•ˆç‡
    
    3. **å…¶ä»–å»ºè®®**ï¼š
       - ç¡®ä¿PDFæ–‡ä»¶å¯å¤åˆ¶ï¼ˆéå›¾ç‰‡æ‰«æä»¶ï¼‰
       - è‹¥æ–‡ä»¶åŠ å¯†ï¼Œè¯·å…ˆè§£å¯†å†ä¸Šä¼ 
       - å¯¹äºç‰¹åˆ«é•¿çš„æ–‡ä»¶ï¼Œå¯é€‚å½“å¢åŠ æœ€å¤§æ¡æ¬¾æ•°é‡
    
    ### åŸºæœ¬ä½¿ç”¨æµç¨‹
    1. ä¸Šä¼ ç›®æ ‡æ”¿ç­–æ–‡ä»¶å’Œå¾…æ¯”å¯¹æ–‡ä»¶
    2. é…ç½®APIå¯†é’¥ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
    3. æ ¹æ®æ–‡ä»¶ç‰¹ç‚¹è°ƒæ•´è§£æå‚æ•°
    4. ç‚¹å‡»"åˆ†æ"æŒ‰é’®ç”Ÿæˆæ¯”å¯¹ç»“æœ
    5. æŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½æŠ¥å‘Š
    """)
