import streamlit as st
import re
import time
import requests
import json
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import tempfile
import os
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import jieba  # ç”¨äºä¸­æ–‡åˆ†è¯ï¼Œæé«˜åŒ¹é…ç²¾åº¦

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¡æ¬¾å¼æ”¿ç­–æ¯”å¯¹åˆ†æå·¥å…·",
    page_icon="ğŸ“œ",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .stButton>button {
        margin-top: 1rem;
    }
    .analysis-box {
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 1rem;
        margin-top: 1rem;
        background-color: #f9f9f9;
    }
    .matched-clause {
        border-left: 4px solid #28a745;
        padding: 0.75rem;
        margin: 1rem 0;
        background-color: #f8fff8;
    }
    .non-compliant {
        border-left: 4px solid #dc3545;
        padding: 0.75rem;
        margin: 1rem 0;
        background-color: #fff5f5;
    }
    .difference-section {
        border-left: 4px solid #ffc107;
        padding: 0.75rem;
        margin: 0.5rem 0;
        background-color: #fffcf2;
    }
    .summary-box {
        border: 1px solid #007bff;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        background-color: #f0f7ff;
    }
    .parse-info {
        font-size: 0.9rem;
        color: #6c757d;
        margin-top: 0.5rem;
    }
    .clause-item {
        padding: 0.5rem;
        margin: 0.25rem 0;
        border-radius: 3px;
        background-color: #f0f2f6;
    }
    .highlight-conflict { background-color: #ffeeba; padding: 2px 4px; border-radius: 3px; }
    .clause-box { border-left: 4px solid #007bff; padding: 10px; margin: 10px 0; background-color: #f8f9fa; }
    .compliance-ok { border-left: 4px solid #28a745; }
    .compliance-warning { border-left: 4px solid #ffc107; }
    .compliance-conflict { border-left: 4px solid #dc3545; }
    .model-response { background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin: 10px 0; }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'target_clauses' not in st.session_state:
    st.session_state.target_clauses = {}  # {æ¡æ¬¾å·: å†…å®¹}
if 'compare_files' not in st.session_state:
    st.session_state.compare_files = {}  # {æ–‡ä»¶å: {æ¡æ¬¾: {}, åˆ†æç»“æœ: {åŒ¹é…ç»“æœ: {}, æ€»ç»“: ""}}}
if 'current_file' not in st.session_state:
    st.session_state.current_file = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = os.getenv("QWEN_API_KEY", "")
if 'parse_precision' not in st.session_state:
    st.session_state.parse_precision = "ä¸­ç­‰"  # è§£æç²¾åº¦

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“œ æ¡æ¬¾å¼æ”¿ç­–æ¯”å¯¹åˆ†æå·¥å…·")
st.markdown("è§£ææ‰€æœ‰æ¡æ¬¾ï¼Œä»…åˆ†ææ»¡è¶³åˆè§„æ€§åŒ¹é…çš„å‰50æ¡ï¼ˆå·²ä¼˜åŒ–ï¼šè·³è¿‡è¡¨æ ¼å†…å®¹ï¼‰")
st.markdown("---")

# æ¡æ¬¾æå–è®¾ç½®
st.sidebar.subheader("æ¡æ¬¾æå–è®¾ç½®")

# è§£æç²¾åº¦è®¾ç½®
st.session_state.parse_precision = st.sidebar.select_slider(
    "æ¡æ¬¾è§£æç²¾åº¦",
    options=["å®½æ¾", "ä¸­ç­‰", "ä¸¥æ ¼"],
    value=st.session_state.parse_precision,
    help="å®½æ¾ï¼šæå–æ›´å¤šå¯èƒ½çš„æ¡æ¬¾ï¼›ä¸¥æ ¼ï¼šåªæå–æ˜ç¡®ç¬¦åˆæ ¼å¼çš„æ¡æ¬¾"
)

# è¡¨æ ¼è¿‡æ»¤è®¾ç½®
filter_tables = st.sidebar.checkbox(
    "è¿‡æ»¤è¡¨æ ¼å†…å®¹",
    value=True,
    help="å¯ç”¨åå°†å°è¯•è¯†åˆ«å¹¶è·³è¿‡PDFä¸­çš„è¡¨æ ¼å†…å®¹"
)

# APIé…ç½®
with st.expander("ğŸ”‘ API é…ç½®", expanded=not st.session_state.api_key):
    st.session_state.api_key = st.text_input("è¯·è¾“å…¥Qwen APIå¯†é’¥", value=st.session_state.api_key, type="password")
    model_option = st.selectbox(
        "é€‰æ‹©Qwenæ¨¡å‹",
        ["qwen-turbo", "qwen-plus", "qwen-max"],
        index=0  # é»˜è®¤ä½¿ç”¨è½»é‡ç‰ˆ
    )
    st.caption("æç¤ºï¼šå¯ä»é˜¿é‡Œäº‘DashScopeå¹³å°è·å–APIå¯†é’¥")

# è¾…åŠ©å‡½æ•°ï¼šåˆ¤æ–­æ–‡æœ¬æ˜¯å¦å¯èƒ½æ¥è‡ªè¡¨æ ¼
def is_likely_table(text):
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦å¯èƒ½æ¥è‡ªè¡¨æ ¼ï¼Œè¿”å›Trueè¡¨ç¤ºå¯èƒ½æ˜¯è¡¨æ ¼å†…å®¹"""
    if not text:
        return False
    
    # è¡¨æ ¼å†…å®¹é€šå¸¸æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
    # 1. åŒ…å«å¤§é‡æ•°å­—
    digit_ratio = len(re.findall(r'\d', text)) / max(len(text), 1)
    if digit_ratio > 0.3:  # æ•°å­—å æ¯”è¶…è¿‡30%
        return True
    
    # 2. åŒ…å«å¤§é‡åˆ†éš”ç¬¦/ç‰¹æ®Šå­—ç¬¦
    separator_chars = r'[|â”ƒâ”†â”‡â•‘+ï¼=â€”_]'
    separator_count = len(re.findall(separator_chars, text))
    if separator_count > 3:  # è¶…è¿‡3ä¸ªåˆ†éš”ç¬¦
        return True
    
    # 3. çŸ­å¥å¯†é›†ï¼ˆè¡¨æ ¼å•å…ƒæ ¼é€šå¸¸è¾ƒçŸ­ï¼‰
    words = text.split()
    if len(words) > 5 and sum(1 for word in words if len(word) < 5) / len(words) > 0.7:
        return True
    
    # 4. åŒ…å«å…¸å‹çš„è¡¨æ ¼æ ‡é¢˜å…³é”®è¯
    table_keywords = ['åºå·', 'ç¼–å·', 'åç§°', 'å•ä½', 'æ•°é‡', 'é‡‘é¢', 'å¤‡æ³¨', 'åˆè®¡', 'å°è®¡']
    keyword_count = sum(1 for kw in table_keywords if kw in text)
    if keyword_count >= 2:  # åŒ…å«2ä¸ªä»¥ä¸Šè¡¨æ ¼å…³é”®è¯
        return True
    
    return False

# ä»1å¯¹1æ¡æ¬¾åˆ†æä¸­æ•´åˆçš„ä¸­æ–‡ä¼˜åŒ–å‡½æ•°
def extract_text_from_pdf(file, filter_tables=True):
    """ä»PDFæå–æ–‡æœ¬ï¼Œä¼˜åŒ–ä¸­æ–‡å¤„ç†ï¼Œå¹¶å¯é€‰æ‹©è¿‡æ»¤è¡¨æ ¼å†…å®¹"""
    try:
        pdf_reader = PdfReader(file)
        text = ""
        table_count = 0
        
        for page in pdf_reader.pages:
            page_text = page.extract_text() or ""
            
            # å¦‚æœéœ€è¦è¿‡æ»¤è¡¨æ ¼ï¼Œå…ˆåˆ†å‰²æ–‡æœ¬ä¸ºæ®µè½å†åˆ¤æ–­
            if filter_tables:
                # ç®€å•åˆ†å‰²æ®µè½ï¼ˆæ ¹æ®æ¢è¡Œï¼‰
                paragraphs = page_text.split('\n')
                filtered_paragraphs = []
                
                for para in paragraphs:
                    # æ¸…ç†æ®µè½
                    cleaned_para = para.strip().replace("  ", "")
                    if not cleaned_para:
                        continue
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºè¡¨æ ¼å†…å®¹
                    if is_likely_table(cleaned_para):
                        table_count += 1
                        continue  # è·³è¿‡è¡¨æ ¼å†…å®¹
                    
                    filtered_paragraphs.append(cleaned_para)
                
                # é‡æ–°ç»„åˆæ®µè½
                page_text = "".join(filtered_paragraphs)
            
            # å¤„ç†ä¸­æ–‡ç©ºæ ¼å’Œæ¢è¡Œé—®é¢˜
            page_text = page_text.replace("  ", "").replace("\n", "").replace("\r", "")
            text += page_text
        
        # æç¤ºè¿‡æ»¤äº†å¤šå°‘è¡¨æ ¼å†…å®¹
        if filter_tables and table_count > 0:
            st.info(f"å·²è·³è¿‡ {table_count} å¤„å¯èƒ½çš„è¡¨æ ¼å†…å®¹")
            
        return text
    except Exception as e:
        st.error(f"æå–æ–‡æœ¬å¤±è´¥: {str(e)}")
        return ""

def split_into_clauses(text):
    """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ¡æ¬¾ï¼Œå¢å¼ºä¸­æ–‡æ¡æ¬¾è¯†åˆ«"""
    # å¢å¼ºä¸­æ–‡æ¡æ¬¾æ¨¡å¼è¯†åˆ«
    patterns = [
        # ä¸­æ–‡æ¡æ¬¾å¸¸è§æ ¼å¼
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+|$)',  # ç¬¬ä¸€æ¡ã€ç¬¬äºŒæ¡æ ¼å¼
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+.*?)(?=[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s+|$)',  # ä¸€ã€äºŒã€ä¸‰ã€æ ¼å¼
        r'(\d+\.\s+.*?)(?=\d+\.\s+|$)',  # 1. 2. 3. æ ¼å¼
        r'(\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+.*?)(?=\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s+|$)',  # (ä¸€) (äºŒ) æ ¼å¼
        r'(\([1-9]+\)\s+.*?)(?=\([1-9]+\)\s+|$)',  # (1) (2) æ ¼å¼
        r'(ã€[^\ã€‘]+ã€‘\s+.*?)(?=ã€[^\ã€‘]+ã€‘\s+|$)'  # ã€æ ‡é¢˜ã€‘æ ¼å¼
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:  # ç¡®ä¿æ‰¾åˆ°è¶³å¤Ÿå¤šçš„æ¡æ¬¾
            return [clause.strip() for clause in clauses if clause.strip()]
    
    # æŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ†å‰²æ®µè½
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    paragraphs = [p.strip() for p in paragraphs if p.strip() and len(p) > 10]  # è¿‡æ»¤è¿‡çŸ­å†…å®¹
    return paragraphs

def chinese_text_similarity(text1, text2):
    """è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦ï¼Œä½¿ç”¨åˆ†è¯ååŒ¹é…"""
    # ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    
    # è®¡ç®—åˆ†è¯åçš„ç›¸ä¼¼åº¦
    return SequenceMatcher(None, words1, words2).ratio()

# ä¼˜åŒ–çš„PDFè§£æå‡½æ•° - è§£ææ‰€æœ‰æ¡æ¬¾ï¼ˆæ•´åˆ1å¯¹1åˆ†æçš„ä¸­æ–‡å¤„ç†ï¼‰
def parse_pdf_by_clauses(file, precision="ä¸­ç­‰", filter_tables=True):
    """è§£æPDFæ–‡ä»¶å¹¶æå–æ‰€æœ‰æ¡æ¬¾ï¼Œä¸é™åˆ¶æ•°é‡ï¼Œä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–è§£æï¼Œå¯é€‰æ‹©è¿‡æ»¤è¡¨æ ¼"""
    try:
        with st.spinner("æ­£åœ¨è§£ææ–‡ä»¶å¹¶æ‹†åˆ†æ‰€æœ‰æ¡æ¬¾..."):
            # ä½¿ç”¨1å¯¹1åˆ†æä¸­çš„æ–‡æœ¬æå–æ–¹æ³•ï¼ŒåŠ å…¥è¡¨æ ¼è¿‡æ»¤
            full_text = extract_text_from_pdf(file, filter_tables=filter_tables)
            total_pages = len(PdfReader(file).pages)  # è·å–æ€»é¡µæ•°
            
            # æ–‡æœ¬é¢„å¤„ç† - å¢å¼ºæ¡æ¬¾è¯†åˆ«
            full_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', full_text)  # ç§»é™¤æ§åˆ¶å­—ç¬¦
            full_text = re.sub(r'\s+', ' ', full_text).strip()  # ç»Ÿä¸€ç©ºç™½å­—ç¬¦
            
            # ä½¿ç”¨1å¯¹1åˆ†æä¸­çš„æ¡æ¬¾åˆ†å‰²é€»è¾‘
            clauses_list = split_into_clauses(full_text)
            
            # ä¸ºæ¡æ¬¾æ·»åŠ ç¼–å·å¹¶è¿‡æ»¤
            clauses = {}
            for i, clause in enumerate(clauses_list, 1):
                # æå–æ¡æ¬¾ç¼–å·ï¼ˆå¦‚æœæœ‰ï¼‰
                clause_num = str(i)  # é»˜è®¤ä½¿ç”¨ç´¢å¼•ä½œä¸ºç¼–å·
                num_match = None
                
                # å°è¯•ä»æ¡æ¬¾æ–‡æœ¬ä¸­æå–ç¼–å·
                if re.search(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡', clause):
                    num_match = re.search(r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+)æ¡', clause)
                elif re.search(r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€', clause):
                    num_match = re.search(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ã€', clause)
                elif re.search(r'\d+\.', clause):
                    num_match = re.search(r'(\d+)\.', clause)
                elif re.search(r'\(([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)\)', clause):
                    num_match = re.search(r'\(([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)\)', clause)
                elif re.search(r'\(([1-9]+)\)', clause):
                    num_match = re.search(r'\(([1-9]+)\)', clause)
                elif re.search(r'ã€[^\ã€‘]+ã€‘', clause):
                    num_match = re.search(r'ã€([^\ã€‘]+)ã€‘', clause)
                
                if num_match:
                    clause_num = num_match.group(1)
                    # æ¸…ç†æ¡æ¬¾å†…å®¹ï¼Œç§»é™¤ç¼–å·éƒ¨åˆ†
                    clause_content = re.sub(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s*', '', clause)
                    clause_content = re.sub(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€\s*', '', clause_content)
                    clause_content = re.sub(r'^\d+\.\s*', '', clause_content)
                    clause_content = re.sub(r'^\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\)\s*', '', clause_content)
                    clause_content = re.sub(r'^\([1-9]+\)\s*', '', clause_content)
                    clause_content = re.sub(r'^ã€[^\ã€‘]+ã€‘\s*', '', clause_content)
                else:
                    clause_content = clause
                
                # æ ¹æ®ç²¾åº¦è¿‡æ»¤æ¡æ¬¾
                if precision == "ä¸¥æ ¼" and len(clause_content) > 50:
                    clauses[clause_num] = clause_content.strip()
                elif precision == "ä¸­ç­‰" and len(clause_content) > 30:
                    clauses[clause_num] = clause_content.strip()
                elif precision == "å®½æ¾" and len(clause_content) > 20:
                    clauses[clause_num] = clause_content.strip()
            
            st.success(f"å…±è§£æ {total_pages} é¡µï¼ŒæˆåŠŸæå– {len(clauses)} æ¡æ¡æ¬¾")
            return clauses
            
    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
        return {}

# è°ƒç”¨Qwen APIè¿›è¡Œæ¡æ¬¾æ¯”å¯¹åˆ†æï¼ˆæ•´åˆ1å¯¹1åˆ†æçš„APIè°ƒç”¨æ–¹å¼ï¼‰
def call_qwen_api(prompt, api_key, model="qwen-turbo"):
    """è°ƒç”¨Qwen APIè¿›è¡Œæ¡æ¬¾æ¯”å¯¹åˆ†æï¼Œä½¿ç”¨ä¼˜åŒ–çš„APIè¯·æ±‚æ ¼å¼"""
    if not api_key:
        st.error("è¯·å…ˆé…ç½®APIå¯†é’¥")
        return None
    
    try:
        with st.spinner("æ­£åœ¨åˆ†ææ¡æ¬¾..."):
            url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1000
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                response_data = response.json()
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    return response_data["choices"][0]["message"]["content"]
                else:
                    st.error(f"APIè¿”å›æ ¼å¼å¼‚å¸¸: {response_data}")
                    return None
            else:
                st.error(f"APIè°ƒç”¨å¤±è´¥: çŠ¶æ€ç  {response.status_code}, å“åº”: {response.text}")
                return None
                
    except requests.exceptions.Timeout:
        st.error("APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•")
        return None
    except Exception as e:
        st.error(f"APIè¯·æ±‚é”™è¯¯: {str(e)}")
        return None

# åˆè§„æ€§åˆ†æå‡½æ•° - åªåˆ†ææ»¡è¶³åˆè§„æ€§çš„å‰50æ¡åŒ¹é…æ¡æ¬¾
def analyze_clause_matches(target_clauses, compare_clauses, api_key, model):
    """æŒ‰æ¡æ¬¾åŒ¹é…è¿›è¡Œåˆè§„æ€§åˆ†æï¼Œä»…ä¿ç•™æ»¡è¶³åˆè§„æ€§çš„å‰50æ¡"""
    if not target_clauses or not compare_clauses:
        st.warning("ç¼ºå°‘æ¡æ¬¾å†…å®¹ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return None, None, 0, 0
    
    # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„æ¡æ¬¾ï¼ˆæ¡æ¬¾å·ç›¸åŒï¼‰
    all_matched_clause_nums = [num for num in target_clauses if num in compare_clauses]
    total_matched = len(all_matched_clause_nums)
    
    if not all_matched_clause_nums:
        # å°è¯•åŸºäºå†…å®¹ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆæ¥è‡ª1å¯¹1åˆ†æçš„ä¼˜åŒ–ï¼‰
        st.info("æœªæ‰¾åˆ°ç¼–å·åŒ¹é…çš„æ¡æ¬¾ï¼Œå°è¯•åŸºäºå†…å®¹ç›¸ä¼¼åº¦åŒ¹é…...")
        target_list = [(num, content) for num, content in target_clauses.items()]
        compare_list = [(num, content) for num, content in compare_clauses.items()]
        
        matched_pairs = []
        used_indices = set()
        
        for i, (t_num, t_content) in enumerate(target_list):
            best_match = None
            best_ratio = 0.3  # ä¸­æ–‡åŒ¹é…é˜ˆå€¼
            best_j = -1
            
            for j, (c_num, c_content) in enumerate(compare_list):
                if j not in used_indices:
                    ratio = chinese_text_similarity(t_content, c_content)
                    if ratio > best_ratio:
                        best_ratio = ratio
                        best_match = (c_num, c_content)
                        best_j = j
            
            if best_match:
                matched_pairs.append((t_num, best_match[0], best_ratio))
                used_indices.add(best_j)
        
        if matched_pairs:
            all_matched_clause_nums = [(t_num, c_num) for t_num, c_num, _ in matched_pairs]
            total_matched = len(matched_pairs)
            st.info(f"åŸºäºå†…å®¹ç›¸ä¼¼åº¦æ‰¾åˆ° {total_matched} æ¡å¯èƒ½åŒ¹é…çš„æ¡æ¬¾")
        else:
            st.info("æœªæ‰¾åˆ°åŒ¹é…çš„æ¡æ¬¾")
            return {}, "æœªæ‰¾åˆ°åŒ¹é…çš„æ¡æ¬¾ï¼Œæ— æ³•è¿›è¡Œåˆè§„æ€§åˆ†æã€‚", 0, total_matched
    
    # åˆ†ææ¯ä¸ªåŒ¹é…çš„æ¡æ¬¾ï¼Œç­›é€‰åˆè§„çš„
    compliant_results = {}
    non_compliant_results = {}
    
    with st.spinner(f"æ­£åœ¨åˆ†æ {total_matched} æ¡åŒ¹é…æ¡æ¬¾ï¼Œç­›é€‰åˆè§„æ¡æ¬¾..."):
        progress_bar = st.progress(0)
        for i, item in enumerate(all_matched_clause_nums):
            # å¤„ç†ä¸¤ç§åŒ¹é…æ–¹å¼çš„ç»“æœ
            if isinstance(item, tuple):
                t_num, c_num = item  # ç›¸ä¼¼åº¦åŒ¹é…çš„ç»“æœ
            else:
                t_num = c_num = item  # ç¼–å·åŒ¹é…çš„ç»“æœ
                
            target_content = target_clauses[t_num]
            compare_content = compare_clauses[c_num]
            
            # ç”Ÿæˆæ¡æ¬¾æ¯”å¯¹æç¤ºï¼Œç‰¹åˆ«è¦æ±‚åˆ¤æ–­åˆè§„æ€§ï¼ˆä¼˜åŒ–ä¸­æ–‡æç¤ºï¼‰
            prompt = f"""
            è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä¸¤ä¸ªä¸­æ–‡æ¡æ¬¾çš„åˆè§„æ€§ï¼š
            
            ç›®æ ‡æ¡æ¬¾ï¼ˆç¬¬{t_num}æ¡ï¼‰ï¼š
            {target_content[:300]}
            
            å¾…æ¯”å¯¹æ¡æ¬¾ï¼ˆç¬¬{c_num}æ¡ï¼‰ï¼š
            {compare_content[:300]}
            
            åˆ†æè¦æ±‚ï¼š
            1. é¦–å…ˆæ˜ç¡®åˆ¤æ–­å¾…æ¯”å¯¹æ¡æ¬¾æ˜¯å¦ç¬¦åˆç›®æ ‡æ¡æ¬¾è¦æ±‚ï¼ˆç”¨"åˆè§„"æˆ–"ä¸åˆè§„"å¼€å¤´ï¼‰
            2. æŒ‡å‡ºä¸¤è€…çš„ä¸»è¦å·®å¼‚ç‚¹ï¼ˆå¦‚æ— å·®å¼‚åˆ™è¯´æ˜ä¸€è‡´ï¼‰
            3. åˆ†æå·®å¼‚å¯èƒ½å¸¦æ¥çš„å½±å“
            4. æ³¨æ„ä¸­æ–‡æ³•å¾‹/åˆåŒæ¡æ¬¾ä¸­å¸¸ç”¨è¡¨è¿°çš„ç»†å¾®å·®åˆ«ï¼Œå¦‚"åº”å½“"ä¸"å¿…é¡»"ã€"ä¸å¾—"ä¸"ç¦æ­¢"ç­‰
            5. ç”¨ç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡300å­—ï¼‰è¾“å‡ºåˆ†æç»“æœ
            """
            
            # è°ƒç”¨APIåˆ†æ
            result = call_qwen_api(prompt, api_key, model)
            if result:
                # åˆ¤æ–­æ˜¯å¦åˆè§„ï¼ˆåŸºäºAPIè¿”å›ç»“æœçš„å¼€å¤´ï¼‰
                if result.strip().startswith("åˆè§„"):
                    compliant_results[t_num] = {
                        "target_num": t_num,
                        "compare_num": c_num,
                        "target": target_content,
                        "compare": compare_content,
                        "analysis": result,
                        "compliant": True
                    }
                else:
                    non_compliant_results[t_num] = {
                        "target_num": t_num,
                        "compare_num": c_num,
                        "target": target_content,
                        "compare": compare_content,
                        "analysis": result,
                        "compliant": False
                    }
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((i + 1) / len(all_matched_clause_nums))
        
        # é™åˆ¶åªä¿ç•™å‰50æ¡åˆè§„æ¡æ¬¾
        max_analyze = 50
        final_compliant = dict(list(compliant_results.items())[:max_analyze])
        
        # æ˜¾ç¤ºåˆ†ææ•°é‡ä¿¡æ¯
        st.info(f"""
        åˆ†æå®Œæˆï¼š
        - æ€»åŒ¹é…æ¡æ¬¾æ•°ï¼š{total_matched} æ¡
        - åˆè§„æ¡æ¬¾æ•°ï¼š{len(compliant_results)} æ¡
        - æœ¬æ¬¡åˆ†æå±•ç¤ºå‰ {min(len(compliant_results), max_analyze)} æ¡åˆè§„æ¡æ¬¾
        """)
    
    # ç”Ÿæˆæ€»ä½“æ€»ç»“ï¼ˆåŸºäºåˆè§„æ¡æ¬¾ï¼‰
    summary_prompt = f"""
    ä»¥ä¸‹æ˜¯ç›®æ ‡æ”¿ç­–æ–‡ä»¶ä¸å¾…æ¯”å¯¹æ–‡ä»¶ä¸­åˆè§„æ¡æ¬¾çš„åˆ†æç»“æœï¼š
    {json.dumps(final_compliant, ensure_ascii=False, indent=2)}
    
    é¢å¤–ä¿¡æ¯ï¼š
    - æ€»åŒ¹é…æ¡æ¬¾æ•°ï¼š{total_matched} æ¡
    - åˆè§„æ¡æ¬¾æ•°ï¼š{len(compliant_results)} æ¡
    
    è¯·åŸºäºä»¥ä¸Šåˆ†æï¼Œç”¨ç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡300å­—ï¼‰æ€»ç»“ï¼š
    1. æ€»ä½“åˆè§„æ€§æƒ…å†µ
    2. ä¸»è¦å·®å¼‚ç‚¹æ±‡æ€»
    3. ç®€è¦çš„åˆè§„å»ºè®®
    """
    
    summary = call_qwen_api(summary_prompt, api_key, model) or "æ— æ³•ç”Ÿæˆæ€»ç»“ï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚"
    
    return final_compliant, summary, len(compliant_results), total_matched

# ç”ŸæˆWordæ–‡æ¡£
def generate_word_document(matched_results, summary, target_filename, compare_filename, total_compliant, total_matched):
    """ç”ŸæˆWordæ ¼å¼åˆ†ææŠ¥å‘Š"""
    try:
        doc = Document()
        
        # æ ‡é¢˜
        title = doc.add_heading("æ”¿ç­–æ–‡ä»¶æ¡æ¬¾æ¯”å¯¹åˆ†ææŠ¥å‘Š", 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # åŸºæœ¬ä¿¡æ¯
        doc.add_paragraph(f"ç›®æ ‡æ”¿ç­–æ–‡ä»¶: {target_filename}")
        doc.add_paragraph(f"å¾…æ¯”å¯¹æ–‡ä»¶: {compare_filename}")
        doc.add_paragraph(f"åˆ†ææ—¥æœŸ: {time.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        doc.add_paragraph(f"æ€»åŒ¹é…æ¡æ¬¾æ•°: {total_matched}")
        doc.add_paragraph(f"åˆè§„æ¡æ¬¾æ•°: {total_compliant}")
        doc.add_paragraph(f"æœ¬æ¬¡æŠ¥å‘Šåˆ†ææ¡æ¬¾æ•°: {len(matched_results)}")
        doc.add_paragraph("")
        
        # æ€»ä½“æ€»ç»“
        doc.add_heading("ä¸€ã€æ€»ä½“æ€»ç»“", level=1)
        for para in re.split(r'\n+', summary):
            if para.strip():
                doc.add_paragraph(para.strip())
        
        # åˆè§„æ¡æ¬¾è¯¦ç»†åˆ†æ
        doc.add_heading("äºŒã€åˆè§„æ¡æ¬¾è¯¦ç»†åˆ†æ", level=1)
        
        for clause_num, details in matched_results.items():
            doc.add_heading(f"ç›®æ ‡æ¡æ¬¾ç¬¬{details['target_num']}æ¡ vs å¾…æ¯”å¯¹æ¡æ¬¾ç¬¬{details['compare_num']}æ¡", level=2)
            
            p = doc.add_paragraph("ç›®æ ‡æ¡æ¬¾å†…å®¹ï¼š")
            p.style = 'Heading 3'
            doc.add_paragraph(details["target"])
            
            p = doc.add_paragraph("å¾…æ¯”å¯¹æ¡æ¬¾å†…å®¹ï¼š")
            p.style = 'Heading 3'
            doc.add_paragraph(details["compare"])
            
            p = doc.add_paragraph("åˆ†æç»“æœï¼š")
            p.style = 'Heading 3'
            for para in re.split(r'\n+', details["analysis"]):
                if para.strip():
                    doc.add_paragraph(para.strip())
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
            doc.save(tmp.name)
            return tmp.name
            
    except Exception as e:
        st.error(f"ç”ŸæˆWordæ–‡æ¡£å¤±è´¥: {str(e)}")
        return None

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 2], gap="large")

with col1:
    st.subheader("ç›®æ ‡æ”¿ç­–æ–‡ä»¶")
    st.caption("ä½œä¸ºåŸºå‡†çš„æ”¿ç­–æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è§£ææ‰€æœ‰æ¡æ¬¾")
    target_file = st.file_uploader("ä¸Šä¼ ç›®æ ‡æ”¿ç­–æ–‡ä»¶ (PDF)", type="pdf", key="target")
    
    if target_file:
        # è§£æç›®æ ‡æ–‡ä»¶æ‰€æœ‰æ¡æ¬¾ï¼Œåº”ç”¨è¡¨æ ¼è¿‡æ»¤è®¾ç½®
        st.session_state.target_clauses = parse_pdf_by_clauses(
            target_file, 
            precision=st.session_state.parse_precision,
            filter_tables=filter_tables
        )
        
        with st.expander(f"æŸ¥çœ‹æå–çš„æ‰€æœ‰æ¡æ¬¾ (å…± {len(st.session_state.target_clauses)} æ¡)"):
            for num, content in st.session_state.target_clauses.items():
                display_text = content[:150] + "..." if len(content) > 150 else content
                st.markdown(f'<div class="clause-item"><strong>ç¬¬{num}æ¡:</strong> {display_text}</div>', unsafe_allow_html=True)
    
    # å¤šæ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("å¾…æ¯”å¯¹æ–‡ä»¶")
    st.caption("å¯ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œç³»ç»Ÿå°†è§£ææ‰€æœ‰æ¡æ¬¾å¹¶æŒ‰ç¼–å·æˆ–å†…å®¹åŒ¹é…")
    compare_files = st.file_uploader(
        "ä¸Šä¼ å¾…æ¯”å¯¹æ–‡ä»¶ (PDF)", 
        type="pdf", 
        key="compare",
        accept_multiple_files=True
    )
    
    # å¤„ç†ä¸Šä¼ çš„å¤šä¸ªæ–‡ä»¶
    if compare_files:
        for file in compare_files:
            if file.name not in st.session_state.compare_files:
                # è§£æå¾…æ¯”å¯¹æ–‡ä»¶æ‰€æœ‰æ¡æ¬¾ï¼Œåº”ç”¨è¡¨æ ¼è¿‡æ»¤è®¾ç½®
                clauses = parse_pdf_by_clauses(
                    file, 
                    precision=st.session_state.parse_precision,
                    filter_tables=filter_tables
                )
                # ç¡®ä¿æ–°æ–‡ä»¶çš„å­—å…¸ç»“æ„å®Œæ•´
                st.session_state.compare_files[file.name] = {
                    "clauses": clauses,
                    "matched_results": None,
                    "summary": None,
                    "total_compliant": 0,  # åˆè§„æ¡æ¬¾æ€»æ•°
                    "total_matched": 0     # æ€»åŒ¹é…æ¡æ¬¾æ•°
                }
                st.success(f"âœ… å·²æ·»åŠ  {file.name}ï¼Œæå–åˆ° {len(clauses)} æ¡æ¡æ¬¾")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„å¾…æ¯”å¯¹æ–‡ä»¶åˆ—è¡¨
    if st.session_state.compare_files:
        st.subheader("å·²ä¸Šä¼ æ–‡ä»¶")
        for filename in st.session_state.compare_files.keys():
            col_a, col_b = st.columns([3, 1])
            with col_a:
                clause_count = len(st.session_state.compare_files[filename]["clauses"])
                # æ˜¾ç¤ºåˆè§„ä¿¡æ¯ï¼ˆå¦‚æœå·²åˆ†æï¼‰
                if st.session_state.compare_files[filename]["total_compliant"] > 0:
                    st.markdown(f"- {filename} (æ¡æ¬¾æ•°: {clause_count}, åˆè§„: {st.session_state.compare_files[filename]['total_compliant']}/{st.session_state.compare_files[filename]['total_matched']})")
                else:
                    st.markdown(f"- {filename} (æ¡æ¬¾æ•°: {clause_count})")
            with col_b:
                if st.button("åˆ†æ", key=f"analyze_{filename}") and st.session_state.target_clauses:
                    # è¿›è¡Œæ¡æ¬¾åŒ¹é…åˆ†æï¼ˆåªä¿ç•™åˆè§„çš„å‰50æ¡ï¼‰
                    matched_results, summary, total_compliant, total_matched = analyze_clause_matches(
                        st.session_state.target_clauses,
                        st.session_state.compare_files[filename]["clauses"],
                        st.session_state.api_key,
                        model_option
                    )
                    if matched_results is not None:
                        st.session_state.compare_files[filename]["matched_results"] = matched_results
                        st.session_state.compare_files[filename]["summary"] = summary
                        st.session_state.compare_files[filename]["total_compliant"] = total_compliant
                        st.session_state.compare_files[filename]["total_matched"] = total_matched
                        st.session_state.current_file = filename
                        st.success(f"âœ… {filename} åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {total_compliant} æ¡åˆè§„æ¡æ¬¾ï¼ˆå±•ç¤ºå‰ {len(matched_results)} æ¡ï¼‰")

with col2:
    st.subheader("åˆ†æç»“æœ")
    
    # æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©æ ‡ç­¾
    if st.session_state.compare_files:
        st.markdown("**é€‰æ‹©æ–‡ä»¶æŸ¥çœ‹ç»“æœï¼š**")
        cols_per_row = 3
        files = list(st.session_state.compare_files.items())
        rows = (len(files) + cols_per_row - 1) // cols_per_row
        
        for row in range(rows):
            cols = st.columns(cols_per_row)
            for col_idx in range(cols_per_row):
                file_idx = row * cols_per_row + col_idx
                if file_idx < len(files):
                    filename, data = files[file_idx]
                    with cols[col_idx]:
                        # æ˜¾ç¤ºåˆè§„æ•°é‡çŠ¶æ€
                        if "total_compliant" in data and data["total_compliant"] > 0:
                            status = f" ({data['total_compliant']}æ¡åˆè§„)"
                        else:
                            status = ""
                        
                        if st.button(f"{filename.split('.')[0]}{status}", key=f"tab_{filename}"):
                            st.session_state.current_file = filename
    
    # æ˜¾ç¤ºå½“å‰é€‰ä¸­æ–‡ä»¶çš„åˆ†æç»“æœ
    if st.session_state.current_file:
        filename = st.session_state.current_file
        # ç¡®ä¿æ–‡ä»¶æ•°æ®å­˜åœ¨
        if filename in st.session_state.compare_files:
            file_data = st.session_state.compare_files[filename]
            # å®‰å…¨è·å–åŒ¹é…ç»“æœå’Œæ€»ç»“
            matched_results = file_data.get("matched_results", None)
            summary = file_data.get("summary", "")
            total_compliant = file_data.get("total_compliant", 0)
            total_matched = file_data.get("total_matched", 0)
            
            if matched_results is not None:
                # æ˜¾ç¤ºæ€»ä½“æ€»ç»“
                st.markdown("### ğŸ“Š æ€»ä½“åˆ†ææ€»ç»“")
                st.markdown('<div class="summary-box">', unsafe_allow_html=True)
                st.markdown(f"**åŒ¹é…ä¸åˆè§„æ¦‚è§ˆï¼š** æ€»åŒ¹é…æ¡æ¬¾ {total_matched} æ¡ï¼Œå…¶ä¸­åˆè§„æ¡æ¬¾ {total_compliant} æ¡ï¼Œæœ¬æ¬¡å±•ç¤ºå‰ {len(matched_results)} æ¡åˆè§„æ¡æ¬¾  \n")
                for para in re.split(r'\n+', summary):
                    if para.strip():
                        st.markdown(f"{para.strip()}  \n")
                st.markdown('</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºåˆè§„æ¡æ¬¾çš„è¯¦ç»†åˆ†æ
                if matched_results:
                    st.markdown(f"### ğŸ” åˆè§„æ¡æ¬¾è¯¦æƒ… ({len(matched_results)} æ¡)")
                    
                    for clause_num, details in matched_results.items():
                        st.markdown(f'#### ç›®æ ‡æ¡æ¬¾ç¬¬{details["target_num"]}æ¡ vs å¾…æ¯”å¯¹æ¡æ¬¾ç¬¬{details["compare_num"]}æ¡')
                        st.markdown('<div class="matched-clause">', unsafe_allow_html=True)
                        
                        st.markdown("**ç›®æ ‡æ¡æ¬¾å†…å®¹ï¼š**")
                        st.write(details["target"][:500] + "..." if len(details["target"]) > 500 else details["target"])
                        
                        st.markdown("**å¾…æ¯”å¯¹æ¡æ¬¾å†…å®¹ï¼š**")
                        st.write(details["compare"][:500] + "..." if len(details["compare"]) > 500 else details["compare"])
                        
                        st.markdown('<div class="difference-section">', unsafe_allow_html=True)
                        st.markdown("**åˆ†æç»“æœï¼š**")
                        for para in re.split(r'\n+', details["analysis"]):
                            if para.strip():
                                st.markdown(f"{para.strip()}  \n")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        st.markdown('</div>', unsafe_allow_html=True)
                
                # ç”Ÿæˆå¹¶ä¸‹è½½Wordæ–‡æ¡£
                if target_file and matched_results is not None:
                    word_file = generate_word_document(
                        matched_results,
                        summary,
                        target_file.name,
                        filename,
                        total_compliant,
                        total_matched
                    )
                    
                    if word_file:
                        with open(word_file, "rb") as f:
                            st.download_button(
                                label=f"ğŸ’¾ ä¸‹è½½ {filename} çš„åˆ†ææŠ¥å‘Š",
                                data=f,
                                file_name=f"æ”¿ç­–æ¡æ¬¾æ¯”å¯¹æŠ¥å‘Š_{filename}_{time.strftime('%Y%m%d')}.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                        os.unlink(word_file)
            else:
                st.info("è¯·ç‚¹å‡»æ–‡ä»¶æ—çš„'åˆ†æ'æŒ‰é’®ç”Ÿæˆåˆ†æç»“æœ")
        else:
            st.warning("æ‰€é€‰æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©")
    else:
        st.info("è¯·ä¸Šä¼ å¾…æ¯”å¯¹æ–‡ä»¶å¹¶é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶æŸ¥çœ‹åˆ†æç»“æœ")

# å¸®åŠ©ä¿¡æ¯
with st.expander("â„¹ï¸ ä½¿ç”¨å¸®åŠ©"):
    st.markdown("""
    ### å·¥å…·ç‰¹ç‚¹
    1. **å…¨é‡æ¡æ¬¾è§£æ**ï¼šè§£ææ–‡ä»¶ä¸­æ‰€æœ‰ç¬¦åˆæ ¼å¼çš„æ¡æ¬¾ï¼Œä¸è®¾æ•°é‡é™åˆ¶
    2. **è¡¨æ ¼è¿‡æ»¤åŠŸèƒ½**ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶è·³è¿‡PDFä¸­çš„è¡¨æ ¼å†…å®¹ï¼Œæé«˜æ¡æ¬¾è¯†åˆ«å‡†ç¡®æ€§
    3. **åŒé‡åŒ¹é…æœºåˆ¶**ï¼šå…ˆæŒ‰æ¡æ¬¾ç¼–å·åŒ¹é…ï¼Œå†æŒ‰å†…å®¹ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰
    4. **åˆè§„æ€§ç­›é€‰**ï¼šä»…å¯¹æ»¡è¶³åˆè§„æ€§è¦æ±‚çš„æ¡æ¬¾è¿›è¡Œè¯¦ç»†åˆ†æ
    5. **æ•°é‡æ§åˆ¶**ï¼šæœ€å¤šå±•ç¤ºå‰50æ¡åˆè§„æ¡æ¬¾ï¼Œä¿è¯åˆ†ææ•ˆç‡
    6. **æ¸…æ™°ç»Ÿè®¡**ï¼šæ˜¾ç¤ºæ€»åŒ¹é…æ¡æ¬¾æ•°ä¸åˆè§„æ¡æ¬¾æ•°çš„ç»Ÿè®¡ä¿¡æ¯
    
    ### è¡¨æ ¼è¯†åˆ«è¯´æ˜
    ç³»ç»Ÿé€šè¿‡ä»¥ä¸‹ç‰¹å¾è¯†åˆ«è¡¨æ ¼å†…å®¹ï¼š
    - åŒ…å«å¤§é‡æ•°å­—ï¼ˆå æ¯”è¶…è¿‡30%ï¼‰
    - åŒ…å«å¤šä¸ªè¡¨æ ¼åˆ†éš”ç¬¦ï¼ˆå¦‚|ã€â”ƒã€+ç­‰ï¼‰
    - çŸ­å¥å¯†é›†ä¸”åŒ…å«å¤šä¸ªè¡¨æ ¼å…³é”®è¯ï¼ˆå¦‚åºå·ã€åç§°ã€æ•°é‡ç­‰ï¼‰
    
    ### åˆè§„åˆ¤æ–­æ ‡å‡†
    ç³»ç»Ÿé€šè¿‡APIåˆ†æè‡ªåŠ¨åˆ¤æ–­æ¡æ¬¾åˆè§„æ€§ï¼š
    - åˆè§„ï¼šå¾…æ¯”å¯¹æ¡æ¬¾ç¬¦åˆç›®æ ‡æ¡æ¬¾çš„æ ¸å¿ƒè¦æ±‚
    - ä¸åˆè§„ï¼šå¾…æ¯”å¯¹æ¡æ¬¾ä¸ç›®æ ‡æ¡æ¬¾å­˜åœ¨å®è´¨æ€§å·®å¼‚
    
    ### ä½¿ç”¨å»ºè®®
    - ç¡®ä¿ç›®æ ‡æ–‡ä»¶æ¡æ¬¾æ¸…æ™°ï¼Œä¾¿äºç³»ç»Ÿå‡†ç¡®è¯†åˆ«åŒ¹é…å…³ç³»
    - å¯¹äºåŒ…å«å¤§é‡æ¡æ¬¾çš„æ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç­›é€‰åˆè§„æ¡æ¬¾å¹¶é™åˆ¶å±•ç¤ºæ•°é‡
    - åˆ†æç»“æœä¸­çš„æ€»ä½“æ€»ç»“åŸºäºæ‰€æœ‰åˆè§„æ¡æ¬¾ç”Ÿæˆï¼Œåæ˜ æ•´ä½“åˆè§„æƒ…å†µ
    """)
