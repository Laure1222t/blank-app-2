import streamlit as st
from PyPDF2 import PdfReader
from difflib import SequenceMatcher
import base64
import re
import requests
import jieba
import time
import sys
from io import StringIO
from typing import List, Tuple, Optional, Dict

# é¡µé¢è®¾ç½® - å°½å¯èƒ½æ—©åœ°è®¾ç½®
st.set_page_config(
    page_title="é«˜æ•ˆåˆè§„æ€§åˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

# å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
for key in list(st.session_state.keys()):
    if key not in ['api_key', 'analysis_running']:
        del st.session_state[key]

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .stApp { max-width: 1200px; margin: 0 auto; }
    .status-box { padding: 10px; border-radius: 5px; margin: 10px 0; }
    .loading-box { background-color: #e3f2fd; }
    .error-box { background-color: #ffebee; }
    .success-box { background-color: #e8f5e9; }
</style>
""", unsafe_allow_html=True)

# APIé…ç½®
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if 'analysis_running' not in st.session_state:
    st.session_state.analysis_running = False
if 'last_error' not in st.session_state:
    st.session_state.last_error = ""
if 'partial_results' not in st.session_state:
    st.session_state.partial_results = {}

def limited_print(text: str, max_length: int = 500):
    """é™åˆ¶æ‰“å°é•¿åº¦ï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤š"""
    if len(text) > max_length:
        print(f"{text[:max_length]}...")
    else:
        print(text)

def call_qwen_api(prompt: str, api_key: str) -> Optional[str]:
    """ä¼˜åŒ–çš„APIè°ƒç”¨å‡½æ•°ï¼Œå‡å°‘è¶…æ—¶å’Œå†…å­˜é—®é¢˜"""
    try:
        # é™åˆ¶æç¤ºè¯é•¿åº¦
        if len(prompt) > 3000:
            prompt = prompt[:3000] + "...ï¼ˆæç¤ºè¯å·²æˆªæ–­ä»¥æé«˜å¤„ç†æ•ˆç‡ï¼‰"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": "qwen-plus",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2,
            "max_tokens": 1000  # å‡å°‘è¿”å›å†…å®¹é•¿åº¦
        }
        
        # ä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
        response = requests.post(
            QWEN_API_URL,
            headers=headers,
            json=data,
            timeout=30  # ç¼©çŸ­è¶…æ—¶æ—¶é—´
        )
        
        if response.status_code == 200:
            response_json = response.json()
            if "choices" in response_json and len(response_json["choices"]) > 0:
                return response_json["choices"][0]["message"]["content"]
            
        st.warning(f"APIè¿”å›éé¢„æœŸçŠ¶æ€: {response.status_code}")
        return None
                
    except requests.exceptions.Timeout:
        st.session_state.last_error = "APIè¯·æ±‚è¶…æ—¶"
        return None
    except requests.exceptions.RequestException as e:
        st.session_state.last_error = f"ç½‘ç»œé”™è¯¯: {str(e)}"
        return None
    except Exception as e:
        st.session_state.last_error = f"APIå¤„ç†é”™è¯¯: {str(e)}"
        return None

def extract_text_from_pdf(file) -> str:
    """è½»é‡çº§PDFæ–‡æœ¬æå–"""
    try:
        # é™åˆ¶PDFå¤§å°
        if file.size > 10 * 1024 * 1024:  # 10MB
            st.error("æ–‡ä»¶è¿‡å¤§ï¼Œå»ºè®®ä½¿ç”¨10MBä»¥ä¸‹çš„PDF")
            return ""
            
        pdf_reader = PdfReader(file)
        # é™åˆ¶å¤„ç†é¡µæ•°
        max_pages = 20
        pages_to_process = pdf_reader.pages[:max_pages]
        
        text = ""
        for page in pages_to_process:
            page_text = page.extract_text() or ""
            page_text = page_text.replace("  ", "").replace("\n", "").replace("\r", "")
            text += page_text
            # é™åˆ¶æ€»æ–‡æœ¬é•¿åº¦
            if len(text) > 50000:
                text = text[:50000]
                break
                
        return text
    except Exception as e:
        st.session_state.last_error = f"PDFæå–é”™è¯¯: {str(e)}"
        return ""

def split_into_clauses(text: str, max_clauses: int = 20) -> List[str]:
    """æ›´é«˜æ•ˆçš„æ¡æ¬¾åˆ†å‰²"""
    if not text:
        return []
        
    # ç®€åŒ–çš„æ¡æ¬¾è¯†åˆ«æ¨¡å¼
    patterns = [
        r'(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+.*?)(?=ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡\s+|$)',
        r'(\d+\.\s+.*?)(?=\d+\.\s+|$)',
    ]
    
    for pattern in patterns:
        clauses = re.findall(pattern, text, re.DOTALL)
        if len(clauses) > 3:
            return [clause.strip() for clause in clauses if clause.strip()][:max_clauses]
    
    # å¤‡ç”¨åˆ†å‰²æ–¹å¼
    paragraphs = re.split(r'[ã€‚ï¼›ï¼ï¼Ÿ]\s*', text)
    return [p.strip() for p in paragraphs if p.strip() and len(p) > 10][:max_clauses]

def chinese_text_similarity(text1: str, text2: str) -> float:
    """ä¼˜åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå‡å°‘è®¡ç®—é‡"""
    # é™åˆ¶æ–‡æœ¬é•¿åº¦ä»¥æé«˜é€Ÿåº¦
    text1 = text1[:500]
    text2 = text2[:500]
    
    words1 = list(jieba.cut(text1))
    words2 = list(jieba.cut(text2))
    
    # é™åˆ¶åˆ†è¯æ•°é‡
    if len(words1) > 100:
        words1 = words1[:100]
    if len(words2) > 100:
        words2 = words2[:100]
        
    return SequenceMatcher(None, words1, words2).ratio()

def match_clauses_with_base(base_clauses: List[str], target_clauses: List[str]) -> List[Tuple[str, str, float]]:
    """æ›´é«˜æ•ˆçš„æ¡æ¬¾åŒ¹é…"""
    matched_pairs = []
    used_indices = set()
    
    # é™åˆ¶åŒ¹é…æ•°é‡
    max_matches = min(15, len(base_clauses), len(target_clauses))
    
    for i, base_clause in enumerate(base_clauses[:max_matches]):
        best_match = None
        best_ratio = 0.35
        best_idx = -1
        
        # åªæ£€æŸ¥å‰20ä¸ªæ¡æ¬¾ï¼Œæé«˜é€Ÿåº¦
        for idx, target_clause in enumerate(target_clauses[:20]):
            if idx not in used_indices:
                ratio = chinese_text_similarity(base_clause, target_clause)
                if ratio > best_ratio:
                    best_ratio = ratio
                    best_match = target_clause
                    best_idx = idx
        
        if best_match:
            matched_pairs.append((base_clause, best_match, best_ratio))
            used_indices.add(best_idx)
            if len(matched_pairs) >= max_matches:
                break
    
    return matched_pairs

def analyze_compliance_with_base(base_clause: str, target_clause: str, 
                               base_name: str, target_name: str, 
                               api_key: str) -> Optional[str]:
    """ç®€åŒ–çš„åˆè§„æ€§åˆ†æ"""
    # é™åˆ¶æ¡æ¬¾é•¿åº¦
    base_clause = base_clause[:300]
    target_clause = target_clause[:300]
    
    prompt = f"""
    ä»¥{base_name}ä¸ºåŸºå‡†ï¼Œåˆ†æåˆè§„æ€§ï¼š
    
    åŸºå‡†æ¡æ¬¾ï¼š{base_clause}
    ç›®æ ‡æ¡æ¬¾ï¼š{target_clause}
    
    è¯·ç®€è¦å›ç­”ï¼š
    1. ç¬¦åˆç¨‹åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰
    2. ä¸»è¦å·®å¼‚ï¼ˆ1-2ç‚¹ï¼‰
    3. ä¿®æ”¹å»ºè®®
    """
    
    return call_qwen_api(prompt, api_key)

def generate_target_report(matched_pairs: List[Tuple[str, str, float]],
                          base_name: str, target_name: str,
                          api_key: str) -> str:
    """ç”Ÿæˆç›®æ ‡æ–‡ä»¶æŠ¥å‘Šï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰"""
    report = [
        f"æ¡æ¬¾åˆè§„æ€§åˆ†ææŠ¥å‘Š: {target_name} vs {base_name}",
        f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}",
        "="*50 + "\n"
    ]
    
    report.append(f"åˆ†ææ¦‚è¦: å…±åŒ¹é… {len(matched_pairs)} æ¡æ¡æ¬¾\n")
    
    # åˆ†ææ¯å¯¹æ¡æ¬¾
    for i, (base_clause, target_clause, ratio) in enumerate(matched_pairs):
        report.append(f"æ¡æ¬¾å¯¹ {i+1} (ç›¸ä¼¼åº¦: {ratio:.2%})")
        report.append(f"åŸºå‡†æ¡æ¬¾: {base_clause[:150]}...")
        report.append(f"ç›®æ ‡æ¡æ¬¾: {target_clause[:150]}...\n")
        
        # åˆè§„æ€§åˆ†æ
        analysis = analyze_compliance_with_base(
            base_clause, target_clause, 
            base_name, target_name, 
            api_key
        )
        
        if analysis:
            report.append("åˆè§„æ€§åˆ†æ:")
            report.append(analysis)
        else:
            report.append("åˆè§„æ€§åˆ†æ: æ— æ³•è·å–åˆ†æç»“æœ")
        
        report.append("\n" + "-"*50 + "\n")
        
        # ä¿å­˜éƒ¨åˆ†ç»“æœ
        st.session_state.partial_results[target_name] = "\n".join(report)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­
        if st.session_state.last_error:
            report.append(f"\nåˆ†æä¸­æ–­: {st.session_state.last_error}")
            return "\n".join(report)
        
        time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿï¼Œå‡å°‘å¹¶å‘
        
    return "\n".join(report)

def get_download_link(text: str, filename: str) -> str:
    """ç”Ÿæˆä¸‹è½½é“¾æ¥"""
    b64 = base64.b64encode(text.encode()).decode()
    return f'<a href="data:text/plain;base64,{b64}" download="{filename}" style="display:inline-block;padding:8px 16px;background-color:#007bff;color:white;text-decoration:none;border-radius:4px;margin:5px 0;">ä¸‹è½½æŠ¥å‘Š</a>'

def main():
    st.title("é«˜æ•ˆåˆè§„æ€§åˆ†æå·¥å…·")
    st.write("åŸºå‡†æ–‡ä»¶ä¸å¤šç›®æ ‡æ–‡ä»¶æ¡æ¬¾å¯¹æ¯”ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    
    # æ˜¾ç¤ºæœ€åé”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if st.session_state.last_error:
        st.markdown(f'<div class="status-box error-box">âš ï¸ ä¸Šæ¬¡é”™è¯¯: {st.session_state.last_error}</div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.subheader("è®¾ç½®")
        api_key = st.text_input("Qwen APIå¯†é’¥", type="password", key="api_key")
        max_clauses = st.slider("æœ€å¤§æ¡æ¬¾æ•°/æ–‡ä»¶", 5, 30, 10)
        st.info("å‡å°‘æ¡æ¬¾æ•°å¯æé«˜é€Ÿåº¦ï¼Œé™ä½åŠ è½½å¤±è´¥æ¦‚ç‡")
    
    # æ–‡ä»¶ä¸Šä¼ 
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("åŸºå‡†æ–‡ä»¶")
        base_file = st.file_uploader("ä¸Šä¼ åŸºå‡†PDF", type="pdf", key="base_file")
    
    with col2:
        st.subheader("ç›®æ ‡æ–‡ä»¶")
        target_files = st.file_uploader(
            "ä¸Šä¼ ç›®æ ‡PDFï¼ˆå¯å¤šä¸ªï¼‰", 
            type="pdf", 
            key="target_files",
            accept_multiple_files=True
        )
    
    # æ§åˆ¶æŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        start_btn = st.button("å¼€å§‹åˆ†æ", 
                             disabled=not (base_file and target_files and api_key) or st.session_state.analysis_running)
    with col2:
        if st.button("é‡ç½®åˆ†æ", disabled=not st.session_state.analysis_running):
            st.session_state.analysis_running = False
            st.session_state.last_error = ""
            st.session_state.partial_results = {}
            st.experimental_rerun()
    
    if start_btn:
        st.session_state.analysis_running = True
        st.session_state.last_error = ""
        
        try:
            # å¤„ç†åŸºå‡†æ–‡ä»¶
            with st.spinner("å¤„ç†åŸºå‡†æ–‡ä»¶..."):
                status_box = st.markdown('<div class="status-box loading-box">å¤„ç†åŸºå‡†æ–‡ä»¶ä¸­...</div>', unsafe_allow_html=True)
                
                base_text = extract_text_from_pdf(base_file)
                if not base_text:
                    st.error("æ— æ³•ä»åŸºå‡†æ–‡ä»¶æå–æ–‡æœ¬")
                    st.session_state.analysis_running = False
                    return
                
                base_clauses = split_into_clauses(base_text, max_clauses)
                status_box.markdown(f'<div class="status-box success-box">åŸºå‡†æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæå–åˆ° {len(base_clauses)} æ¡æ¡æ¬¾</div>', unsafe_allow_html=True)
            
            # å¤„ç†ç›®æ ‡æ–‡ä»¶
            for idx, target_file in enumerate(target_files, 1):
                if not st.session_state.analysis_running:
                    break
                    
                st.subheader(f"åˆ†æç›®æ ‡æ–‡ä»¶ {idx}/{len(target_files)}: {target_file.name}")
                target_status = st.markdown('<div class="status-box loading-box">å‡†å¤‡åˆ†æ...</div>', unsafe_allow_html=True)
                
                # æå–ç›®æ ‡æ–‡ä»¶å†…å®¹
                target_text = extract_text_from_pdf(target_file)
                if not target_text:
                    target_status.markdown('<div class="status-box error-box">æ— æ³•æå–æ–‡ä»¶å†…å®¹ï¼Œè·³è¿‡</div>', unsafe_allow_html=True)
                    continue
                
                target_clauses = split_into_clauses(target_text, max_clauses)
                target_status.markdown(f'<div class="status-box loading-box">æå–åˆ° {len(target_clauses)} æ¡æ¡æ¬¾ï¼Œæ­£åœ¨åŒ¹é…...</div>', unsafe_allow_html=True)
                
                # åŒ¹é…æ¡æ¬¾
                matched_pairs = match_clauses_with_base(base_clauses, target_clauses)
                if not matched_pairs:
                    target_status.markdown('<div class="status-box error-box">æœªæ‰¾åˆ°åŒ¹é…æ¡æ¬¾ï¼Œæ— æ³•åˆ†æ</div>', unsafe_allow_html=True)
                    continue
                
                target_status.markdown(f'<div class="status-box loading-box">æ‰¾åˆ° {len(matched_pairs)} å¯¹åŒ¹é…æ¡æ¬¾ï¼Œæ­£åœ¨åˆ†æ...</div>', unsafe_allow_html=True)
                
                # ç”ŸæˆæŠ¥å‘Š
                report = generate_target_report(
                    matched_pairs,
                    base_file.name,
                    target_file.name,
                    api_key
                )
                
                # æ˜¾ç¤ºç»“æœ
                target_status.markdown('<div class="status-box success-box">åˆ†æå®Œæˆï¼</div>', unsafe_allow_html=True)
                st.markdown(get_download_link(report, f"{target_file.name}_åˆè§„æ€§æŠ¥å‘Š.txt"), unsafe_allow_html=True)
                
                with st.expander("æŸ¥çœ‹æŠ¥å‘Šé¢„è§ˆ"):
                    st.text_area("æŠ¥å‘Šå†…å®¹", report, height=200)
            
            # å®Œæˆæ‰€æœ‰åˆ†æ
            st.session_state.analysis_running = False
            st.balloons()
            st.success("æ‰€æœ‰æ–‡ä»¶åˆ†æå®Œæˆï¼")
                
        except Exception as e:
            st.session_state.analysis_running = False
            st.session_state.last_error = str(e)
            st.markdown(f'<div class="status-box error-box">åˆ†æå‡ºé”™: {str(e)}</div>', unsafe_allow_html=True)
            
            # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
            if st.session_state.partial_results:
                st.subheader("éƒ¨åˆ†åˆ†æç»“æœ")
                for name, report in st.session_state.partial_results.items():
                    st.markdown(get_download_link(report, f"éƒ¨åˆ†_{name}_åˆè§„æ€§æŠ¥å‘Š.txt"), unsafe_allow_html=True)

if __name__ == "__main__":
    main()
    
